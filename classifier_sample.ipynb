{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9144fa89-b6ec-4489-bb5b-e49c6b507b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "from guided_diffusion import dist_util, logger\n",
    "from guided_diffusion.script_util import (\n",
    "    NUM_CLASSES,\n",
    "    model_and_diffusion_defaults,\n",
    "    CNN_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    create_CNN,\n",
    "    add_dict_to_argparser,\n",
    "    args_to_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b89fed3-46be-4980-8d0f-0f477b819dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_argparser():\n",
    "    defaults = dict(\n",
    "        clip_denoised=True,\n",
    "        num_samples=10000,\n",
    "        batch_size=16,\n",
    "        use_ddim=False,\n",
    "        model_path=\"\",\n",
    "        classifier_path=\"\",\n",
    "        classifier_scale=1.0,\n",
    "        doc = \"\"\n",
    "    )\n",
    "    defaults.update(model_and_diffusion_defaults())\n",
    "    defaults.update(CNN_defaults())\n",
    "    parser = argparse.ArgumentParser()\n",
    "    add_dict_to_argparser(parser, defaults)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4a3160b-8736-42c4-996b-79681d2ba059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_dist start\n",
      "Logging to /data/yjpak/guided-diffusion/logs/\n",
      "creating model and diffusion...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (label_emb): Embedding(10, 512)\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttentionLegacy()\n",
       "      (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(896, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(896, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(896, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(896, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args = create_argparser().parse_args()\n",
    "args = create_argparser().parse_args(['--model_path', '/data/yjpak/guided-diffusion/logs/diffusion01/model045000.pt',\n",
    "                                      '--classifier_path', '/data/yjpak/guided-diffusion/logs/CNN_classifier02/classifier_model065000.pt'\n",
    "                                     ])\n",
    "dist_util.setup_dist()\n",
    "log_dir=\"/data/yjpak/guided-diffusion/logs\"\n",
    "logger.configure(dir=os.path.join(log_dir, args.doc))\n",
    "# logger.configure()\n",
    "\n",
    "logger.log(\"creating model and diffusion...\")\n",
    "model, diffusion = create_model_and_diffusion(\n",
    "    **args_to_dict(args, model_and_diffusion_defaults().keys())\n",
    ")\n",
    "model.load_state_dict(\n",
    "    dist_util.load_state_dict(args.model_path, map_location=\"cpu\")\n",
    ")\n",
    "model.to(dist_util.dev())\n",
    "if args.use_fp16:\n",
    "    model.convert_to_fp16()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cbef38f-c398-4654-bbfc-470d6e211cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(clip_denoised=True, num_samples=10000, batch_size=16, use_ddim=False, model_path='/data/yjpak/guided-diffusion/logs/diffusion01/model045000.pt', classifier_path='/data/yjpak/guided-diffusion/logs/CNN_classifier02/classifier_model065000.pt', classifier_scale=1.0, doc='', image_size=80, num_channels=128, num_res_blocks=2, num_heads=4, num_heads_upsample=-1, num_head_channels=-1, attention_resolutions='16,8', channel_mult='', dropout=0.0, class_cond=True, use_checkpoint=False, use_scale_shift_norm=True, resblock_updown=False, use_fp16=False, use_new_attention_order=False, learn_sigma=False, diffusion_steps=1000, noise_schedule='linear', timestep_respacing='', use_kl=False, predict_xstart=False, rescale_timesteps=False, rescale_learned_sigmas=False, classifier_use_fp16=False, input_channels=1, num_classes=10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4278a41f-7a53-4983-9c49-187ccc3c4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_CNN(**args_to_dict(args, CNN_defaults().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "521b4e59-a139-452e-a559-01bc1d69ec73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_2D(\n",
       "  (layer1_conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1_conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1_bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer2_conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer2_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer2_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer2_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer2_bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer3_conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer3_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer3_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer4_conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer4_bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer4_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer4_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer4_bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (emb_layers1): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  )\n",
       "  (emb_layers2): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (emb_layers3): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (emb_layers4): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "449972d2-1207-47cc-adf1-e6ef25270bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module.layer1_conv1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[-0.2334, -0.0625,  0.2735],\n",
       "                        [-0.1974,  0.0436,  0.3831],\n",
       "                        [-0.0957,  0.2618,  0.8061]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3001,  0.2927,  0.3141],\n",
       "                        [ 0.2917,  0.2931,  0.3247],\n",
       "                        [ 0.3013,  0.2982,  0.3497]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2620,  0.2600,  0.3262],\n",
       "                        [ 0.2818,  0.2869,  0.3640],\n",
       "                        [ 0.2788,  0.3036,  0.3963]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0023, -0.1310, -0.1273],\n",
       "                        [-0.0075, -0.0825,  0.2194],\n",
       "                        [ 0.6314,  0.4004,  0.7965]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2209, -0.1791,  0.1665],\n",
       "                        [-0.1433,  0.0375,  0.4468],\n",
       "                        [ 0.1704,  0.3654,  0.9158]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1795, -0.1274, -0.0218],\n",
       "                        [ 0.0299, -0.0897,  0.2432],\n",
       "                        [ 0.6149,  0.4740,  0.6859]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3853, -0.5134, -0.7050],\n",
       "                        [-0.1528, -0.1757, -0.2904],\n",
       "                        [-0.0572,  0.1148, -0.0131]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3957,  0.1264,  0.5726],\n",
       "                        [-0.3216,  0.0721,  0.3614],\n",
       "                        [-0.2518,  0.0419,  0.3603]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2355, -0.3202, -0.3219],\n",
       "                        [-0.3373, -0.2554, -0.2703],\n",
       "                        [-0.3266, -0.3265, -0.3359]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2560, -0.2976, -0.3833],\n",
       "                        [-0.3078, -0.3142, -0.3102],\n",
       "                        [-0.2776, -0.2589, -0.3273]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0392, -0.1360, -0.5550],\n",
       "                        [-0.2564, -0.2303, -0.4441],\n",
       "                        [-0.0741, -0.2704, -0.5320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2827, -0.3540, -0.3775],\n",
       "                        [-0.2940, -0.3026, -0.2666],\n",
       "                        [-0.2907, -0.2610, -0.2978]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1824,  0.2595,  0.7834],\n",
       "                        [ 0.0995,  0.0041,  0.2238],\n",
       "                        [-0.2695, -0.2649, -0.3374]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2630, -0.3158, -0.3619],\n",
       "                        [-0.3049, -0.2614, -0.2875],\n",
       "                        [-0.3672, -0.2899, -0.3263]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4890,  0.4113,  0.5623],\n",
       "                        [ 0.2963,  0.2276,  0.1110],\n",
       "                        [-0.1687, -0.2024, -0.2670]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3218,  0.2278,  0.7862],\n",
       "                        [-0.1970,  0.0749,  0.0955],\n",
       "                        [-0.3303, -0.2034, -0.0599]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2668, -0.3023, -0.3473],\n",
       "                        [-0.3263, -0.3367, -0.2270],\n",
       "                        [-0.3785, -0.2787, -0.3221]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2156,  0.2878,  0.3023],\n",
       "                        [ 0.2966,  0.2139,  0.4115],\n",
       "                        [ 0.2813,  0.2973,  0.3977]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2532,  0.2429,  0.3355],\n",
       "                        [ 0.2759,  0.2652,  0.3666],\n",
       "                        [ 0.2996,  0.3067,  0.4025]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2765, -0.3421, -0.3466],\n",
       "                        [-0.2621, -0.3206, -0.2726],\n",
       "                        [-0.2903, -0.3240, -0.3263]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2421, -0.2664, -0.3433],\n",
       "                        [-0.3309, -0.2808, -0.3370],\n",
       "                        [-0.3441, -0.2913, -0.3400]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2437, -0.3229, -0.3411],\n",
       "                        [-0.2862, -0.2696, -0.3180],\n",
       "                        [-0.3544, -0.2858, -0.3569]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2599, -0.3272, -0.3264],\n",
       "                        [-0.3393, -0.3177, -0.2530],\n",
       "                        [-0.3323, -0.3134, -0.3118]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4643, -0.4758, -0.8427],\n",
       "                        [ 0.0688,  0.0579, -0.0613],\n",
       "                        [ 0.1063,  0.0602,  0.1420]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.8610,  0.2382,  0.3912],\n",
       "                        [ 0.0458, -0.2745,  0.0558],\n",
       "                        [ 0.2063, -0.2502,  0.0134]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3686, -0.1067, -0.3583],\n",
       "                        [ 0.3606, -0.1235, -0.3780],\n",
       "                        [ 0.4249, -0.0221, -0.3778]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4155,  0.1862,  0.3851],\n",
       "                        [ 0.4446,  0.2647,  0.1644],\n",
       "                        [-0.1696, -0.1773, -0.4265]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2579,  0.2364,  0.3221],\n",
       "                        [ 0.2931,  0.2625,  0.4072],\n",
       "                        [ 0.2524,  0.3010,  0.4045]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2720,  0.2529,  0.3285],\n",
       "                        [ 0.2984,  0.2707,  0.3814],\n",
       "                        [ 0.2643,  0.2920,  0.3949]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2653,  0.2581,  0.3289],\n",
       "                        [ 0.2886,  0.2784,  0.3677],\n",
       "                        [ 0.2786,  0.3098,  0.4027]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2485, -0.2940, -0.3677],\n",
       "                        [-0.3327, -0.3066, -0.2919],\n",
       "                        [-0.3138, -0.2870, -0.3306]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2374, -0.3578, -0.3153],\n",
       "                        [-0.3012, -0.2852, -0.2863],\n",
       "                        [-0.2275, -0.3297, -0.3707]]]], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer1_conv1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.0587,  0.0929, -0.0366, -0.0226,  0.0007, -0.0108,  0.0442, -0.0598,\n",
       "                      -0.0598, -0.0123,  0.0004, -0.0108,  0.0223,  0.0080,  0.0684, -0.0483,\n",
       "                       0.0574, -0.0367,  0.0963, -0.0392, -0.0326,  0.0429, -0.0615, -0.0360,\n",
       "                      -0.0554, -0.0166,  0.0244, -0.0135, -0.0626, -0.1634,  0.0638,  0.0445],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer1_bn1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([1.2374, 5.2178, 4.9992, 1.1768, 2.2142, 2.3045, 2.2509, 1.3376, 3.2302,\n",
       "                      2.8356, 2.8045, 2.6500, 1.6867, 3.5312, 2.0996, 1.5389, 3.7292, 4.2485,\n",
       "                      4.8232, 3.2760, 3.6550, 3.8974, 3.9351, 1.9960, 2.0683, 2.2093, 1.5100,\n",
       "                      4.7749, 4.8617, 4.9425, 3.0499, 3.0197], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer1_bn1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([1.0610, 3.6726, 2.0528, 0.5348, 1.3985, 0.7625, 1.3147, 1.1457, 0.7073,\n",
       "                      0.4670, 1.6455, 0.4601, 0.9900, 0.8109, 0.6978, 1.1223, 1.7887, 1.0817,\n",
       "                      2.0179, 0.6361, 1.0825, 1.0379, 1.0213, 0.8834, 0.6834, 0.6226, 0.3379,\n",
       "                      1.6763, 1.8648, 1.9488, 0.5318, 0.7186], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer1_bn1.running_mean',\n",
       "              tensor([ 0.2568,  0.5657,  0.4326,  0.2627,  0.2646,  0.2625, -0.3272,  0.0340,\n",
       "                      -0.5254, -0.4782, -0.4312, -0.4755,  0.1408, -0.4654,  0.3192, -0.0398,\n",
       "                      -0.4179,  0.4242,  0.5648, -0.5101, -0.5057, -0.4308, -0.5358, -0.2766,\n",
       "                       0.1615, -0.0581,  0.2134,  0.4523,  0.4054,  0.3106, -0.4087, -0.4178],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layer1_bn1.running_var',\n",
       "              tensor([0.7676, 0.8348, 0.8415, 0.9741, 0.9991, 0.9046, 0.8899, 0.6556, 0.8197,\n",
       "                      0.8220, 0.9015, 0.8179, 0.7296, 0.8480, 0.7743, 0.6765, 0.8567, 0.8220,\n",
       "                      0.8382, 0.8362, 0.8476, 0.8491, 0.8481, 0.8931, 0.8339, 0.6167, 0.6573,\n",
       "                      0.8383, 0.8414, 0.8538, 0.8439, 0.8142], device='cuda:0')),\n",
       "             ('module.layer1_bn1.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.layer1_conv2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[ 2.1210e-01,  7.2264e-02,  5.1929e-02],\n",
       "                        [-1.6442e-01, -3.9282e-02, -4.6945e-02],\n",
       "                        [-1.4843e-01, -4.9016e-02,  9.7145e-02]],\n",
       "              \n",
       "                       [[ 8.6699e-02, -5.7375e-02, -8.9540e-02],\n",
       "                        [-8.6638e-02, -4.2396e-02, -1.2997e-03],\n",
       "                        [ 8.2992e-02,  9.6519e-02,  1.9571e-01]],\n",
       "              \n",
       "                       [[-5.5948e-02, -5.5907e-02, -4.3515e-02],\n",
       "                        [ 6.0360e-02,  1.6700e-01,  2.0872e-01],\n",
       "                        [ 2.2433e-01,  2.7986e-01,  4.0530e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.4922e-02, -7.6409e-02, -3.4555e-02],\n",
       "                        [ 7.6260e-02,  1.6122e-01,  2.0480e-01],\n",
       "                        [ 2.3411e-01,  2.7948e-01,  4.0421e-01]],\n",
       "              \n",
       "                       [[-1.3597e+00, -3.4256e-01,  1.8510e-01],\n",
       "                        [-8.7141e-02,  8.2717e-03,  1.1384e-01],\n",
       "                        [ 1.5930e-01,  8.0821e-02,  2.1800e-01]],\n",
       "              \n",
       "                       [[-7.0703e-01, -8.3984e-02,  1.8815e-01],\n",
       "                        [-1.2841e-01, -1.0283e-01, -1.1729e-01],\n",
       "                        [ 1.5881e-01,  4.9348e-02,  1.2765e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.9584e-02, -9.7892e-02, -2.7707e-01],\n",
       "                        [-1.3865e-01, -1.5651e-01, -3.1238e-01],\n",
       "                        [-1.4804e-01, -1.7266e-01, -2.7278e-01]],\n",
       "              \n",
       "                       [[-3.3811e-01,  6.1438e-02,  2.8287e-02],\n",
       "                        [-2.1609e-01,  8.6142e-02,  7.1204e-02],\n",
       "                        [-1.8798e-01,  1.9571e-01,  2.9928e-01]],\n",
       "              \n",
       "                       [[-2.7262e-01,  1.3897e-01,  1.4617e-01],\n",
       "                        [-1.1830e-01,  1.9729e-01,  1.7793e-01],\n",
       "                        [-9.9076e-02,  3.1100e-01,  3.6944e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.6655e-01,  1.5770e-01,  1.5815e-01],\n",
       "                        [-1.0945e-01,  2.1623e-01,  1.6745e-01],\n",
       "                        [-9.1229e-02,  3.1503e-01,  3.8649e-01]],\n",
       "              \n",
       "                       [[-1.1493e-01, -3.9435e-01, -5.0494e-02],\n",
       "                        [-2.0783e-01, -4.0392e-01,  5.0555e-02],\n",
       "                        [ 4.6585e-02,  1.1426e-01,  5.0256e-01]],\n",
       "              \n",
       "                       [[ 8.2748e-02, -4.1323e-01, -1.2414e-01],\n",
       "                        [ 1.2086e-01, -4.6547e-01, -1.4206e-02],\n",
       "                        [ 4.0061e-01,  1.9275e-01,  5.6154e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3203e-02, -1.6110e-02, -6.5682e-02],\n",
       "                        [-8.8124e-02, -1.2384e-02,  1.8444e-02],\n",
       "                        [-2.2410e-02,  2.7031e-02,  6.2104e-02]],\n",
       "              \n",
       "                       [[-1.4201e-02, -8.7486e-02, -1.3379e+00],\n",
       "                        [-4.8956e-02,  9.8650e-02, -3.3017e-01],\n",
       "                        [-7.4241e-04,  7.9685e-02,  6.7180e-02]],\n",
       "              \n",
       "                       [[-2.0672e-01, -3.4809e-01, -2.8702e+00],\n",
       "                        [-1.6359e-02,  2.6329e-01, -3.6508e-01],\n",
       "                        [ 1.5705e-02,  1.3816e-01,  1.2196e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2764e-01, -3.3582e-01, -2.8595e+00],\n",
       "                        [ 4.6296e-02,  3.0651e-01, -2.8446e-01],\n",
       "                        [ 4.3325e-02,  1.7823e-01,  1.6665e-01]],\n",
       "              \n",
       "                       [[ 9.3064e-02,  7.3300e-02,  3.6461e-01],\n",
       "                        [ 2.4122e-02,  5.0391e-02, -1.8100e-02],\n",
       "                        [-1.0785e-01, -5.8494e-03, -7.4968e-03]],\n",
       "              \n",
       "                       [[ 1.7178e-01,  1.8181e-01,  5.0841e-01],\n",
       "                        [-6.5873e-02, -4.7206e-02, -1.7535e-01],\n",
       "                        [-6.6247e-02,  1.8311e-02, -4.3502e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4812e-03, -5.1702e-02, -2.7729e-02],\n",
       "                        [ 1.0082e-01, -8.8685e-02, -5.8719e-02],\n",
       "                        [ 2.4515e-01,  7.0362e-04,  2.7497e-02]],\n",
       "              \n",
       "                       [[-4.8141e-01, -3.6223e-01, -3.9475e-01],\n",
       "                        [-3.2692e-01, -3.1171e-01, -2.9692e-01],\n",
       "                        [-2.2466e-01, -1.4424e-01,  1.2710e-02]],\n",
       "              \n",
       "                       [[-1.5650e-02,  4.0515e-02, -7.0217e-02],\n",
       "                        [ 5.5282e-02,  4.1720e-02, -8.5754e-02],\n",
       "                        [ 3.6156e-02,  5.5812e-02,  1.3671e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8670e-02,  9.0214e-02, -3.2311e-02],\n",
       "                        [ 7.4072e-02,  6.2860e-02, -5.1241e-02],\n",
       "                        [ 7.0155e-02,  8.0822e-02,  1.1540e-01]],\n",
       "              \n",
       "                       [[ 7.9613e-01,  2.6573e-01,  1.4434e-01],\n",
       "                        [ 2.8542e-01,  3.8912e-02, -1.9354e-01],\n",
       "                        [ 5.7526e-03, -4.5460e-01, -1.1799e+00]],\n",
       "              \n",
       "                       [[ 8.1779e-01,  3.3609e-01,  1.4593e-01],\n",
       "                        [ 2.9111e-01,  1.1011e-01, -2.3297e-01],\n",
       "                        [-1.0797e-01, -6.4530e-01, -1.4426e+00]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9113e-01, -1.8094e-02,  1.8862e-01],\n",
       "                        [-2.9243e-01,  1.9166e-02,  1.7702e-01],\n",
       "                        [-2.0587e-01,  3.6597e-02,  3.1384e-01]],\n",
       "              \n",
       "                       [[ 3.9932e-02,  1.2531e-01,  2.3656e-02],\n",
       "                        [-9.6741e-01, -3.1917e-01, -3.2731e-02],\n",
       "                        [-1.0505e+00, -3.8472e-01, -3.5573e-02]],\n",
       "              \n",
       "                       [[ 8.0230e-02,  1.4190e-01,  2.2545e-02],\n",
       "                        [-2.8876e+00, -2.9352e-01,  8.3488e-02],\n",
       "                        [-3.0657e+00, -3.6792e-01,  6.1998e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8026e-01,  1.9768e-01,  5.4751e-02],\n",
       "                        [-2.8349e+00, -1.8261e-01,  1.3167e-01],\n",
       "                        [-2.9989e+00, -2.4587e-01,  1.1594e-01]],\n",
       "              \n",
       "                       [[-5.5389e-02,  1.7613e-02,  7.3947e-02],\n",
       "                        [ 5.3244e-02, -1.9738e-02,  7.7984e-02],\n",
       "                        [ 8.0515e-02,  4.1043e-02,  7.0904e-03]],\n",
       "              \n",
       "                       [[-4.1060e-02,  1.5952e-01,  3.2608e-01],\n",
       "                        [-1.1285e-01, -1.0402e-01,  1.2700e-01],\n",
       "                        [-4.2750e-02, -5.6503e-04,  1.1474e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1457e-01,  1.0550e-02,  1.6829e-01],\n",
       "                        [-6.2334e-02,  2.9262e-01,  2.0683e-02],\n",
       "                        [-9.3033e-02,  6.3334e-02,  7.2329e-02]],\n",
       "              \n",
       "                       [[ 8.3167e-01,  1.2353e-02, -1.1767e-01],\n",
       "                        [ 7.9012e-02, -1.8002e-01, -9.8675e-02],\n",
       "                        [ 2.9747e-01, -2.8028e-01, -6.7976e-01]],\n",
       "              \n",
       "                       [[ 7.2241e-01, -2.2217e-02, -1.5854e-01],\n",
       "                        [ 1.2617e-01, -2.9459e-02,  2.4406e-02],\n",
       "                        [ 2.8493e-01, -2.3499e-01, -6.4454e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.8546e-01, -3.8440e-02, -1.6223e-01],\n",
       "                        [ 1.2799e-01, -2.8953e-02,  2.8411e-02],\n",
       "                        [ 2.5962e-01, -2.3533e-01, -6.5850e-01]],\n",
       "              \n",
       "                       [[-7.5754e-02,  1.1216e-01, -1.1607e-01],\n",
       "                        [-5.0127e-02,  1.4139e-01, -2.9836e-02],\n",
       "                        [-3.8414e-01,  1.1534e-01,  2.0577e-01]],\n",
       "              \n",
       "                       [[-3.4389e-02,  2.9425e-02,  3.0828e-01],\n",
       "                        [-2.0251e-01, -2.0339e-02,  2.9617e-01],\n",
       "                        [-2.1688e-01,  5.4795e-02,  6.8663e-01]]]], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer1_conv2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.0102, -0.0111,  0.0107, -0.0050,  0.0051, -0.0101, -0.0008, -0.0039,\n",
       "                       0.0066, -0.0076,  0.0060, -0.0107,  0.0059, -0.0002,  0.0031,  0.0112,\n",
       "                      -0.0120,  0.0019, -0.0105, -0.0028, -0.0002, -0.0011, -0.0026,  0.0091,\n",
       "                       0.0130,  0.0096, -0.0010,  0.0008, -0.0028, -0.0038, -0.0057, -0.0074],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer1_bn2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.5910,  0.0307,  0.5611,  0.4561,  0.3857,  0.4894,  0.4229,  0.4653,\n",
       "                       0.3230, -0.0101,  0.4361, -0.0038, -0.0392,  0.0072,  0.2853,  0.3647,\n",
       "                       0.3724,  0.2014,  0.3186,  0.4653,  0.4830,  0.0110,  0.2643,  0.3247,\n",
       "                       0.2348,  0.2868,  0.4310,  0.3416,  0.2393,  0.5113,  0.6767,  0.4356],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer1_bn2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.2613, -0.2383, -0.3995, -0.2561, -0.4233, -0.1407, -0.1166,  0.2382,\n",
       "                      -0.3159, -0.0601, -0.1615, -0.0345, -0.1703, -0.0532,  0.1236,  0.1537,\n",
       "                       0.1902, -0.0691, -0.4555, -0.0651, -0.0232, -0.0923, -0.2152,  0.0773,\n",
       "                       0.4568, -0.0478, -0.3927, -0.0780,  0.0901, -0.2312, -0.4685, -0.0486],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer1_bn2.running_mean',\n",
       "              tensor([ -11.0658,   36.2804,  -85.7374,   26.9193, -250.1003,   35.8575,\n",
       "                       -43.0855,  136.0199,  100.8556,   61.1165,  198.4805,   41.4390,\n",
       "                        49.3211,   44.6507,   -1.4809,  130.9539,  120.4575,   61.1346,\n",
       "                      -235.5904,   56.4413,   89.1244,  245.6003,   28.1593,   84.9545,\n",
       "                        72.4695,   65.9119,  -87.7024,    7.9200,   75.7359,   33.9664,\n",
       "                      -105.7326, -120.1378], device='cuda:0')),\n",
       "             ('module.layer1_bn2.running_var',\n",
       "              tensor([2048.3459, 1050.9388, 3483.8540, 2274.8423, 4449.7085, 2224.1873,\n",
       "                      2049.7009, 6138.3140, 1421.4624,  188.2319, 2093.4255,  601.4984,\n",
       "                       860.9753,  653.9088,  544.1246, 6793.9097, 6707.3218, 1993.1051,\n",
       "                      1323.6672,  788.1218, 3680.4287, 5891.7402, 2030.2965, 1309.3820,\n",
       "                       808.8694, 3451.0808, 3386.1421, 1471.1353, 3603.5801, 2185.2878,\n",
       "                      8161.5151, 1279.9323], device='cuda:0')),\n",
       "             ('module.layer1_bn2.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.layer2_conv1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[ 8.4453e-02,  7.0514e-02,  1.4610e-01],\n",
       "                        [-4.2175e-01, -3.5958e-01, -5.2829e-02],\n",
       "                        [-3.2287e-01, -4.9898e-01, -4.2292e-01]],\n",
       "              \n",
       "                       [[ 8.3872e-03,  3.1712e-01,  4.6237e-02],\n",
       "                        [-1.7863e-02,  1.5385e-01, -3.3806e-01],\n",
       "                        [ 1.3532e-01,  3.3669e-01, -1.2810e-01]],\n",
       "              \n",
       "                       [[ 4.0001e-01,  4.6190e-01,  3.4410e-01],\n",
       "                        [-1.2543e-01, -1.7342e-01, -1.2823e-01],\n",
       "                        [ 3.0256e-01,  1.6272e-01,  1.7565e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2445e-02,  1.4701e-01,  1.0988e-01],\n",
       "                        [ 1.5527e-01, -5.8056e-02, -8.6028e-02],\n",
       "                        [-2.5777e-02, -2.8683e-01, -1.0158e-01]],\n",
       "              \n",
       "                       [[ 3.1581e-01,  1.4262e-02,  7.9023e-01],\n",
       "                        [ 3.3582e-01, -9.6148e-02,  5.1162e-01],\n",
       "                        [ 2.8306e-01, -2.8980e-02,  6.4487e-01]],\n",
       "              \n",
       "                       [[-4.6409e-01,  1.3465e-01, -5.7182e-02],\n",
       "                        [ 1.0153e-01,  2.8104e-01,  3.7344e-02],\n",
       "                        [-1.0721e-01,  2.9755e-02, -3.6522e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9606e-01,  6.1241e-01,  8.1453e-01],\n",
       "                        [-2.0560e-01, -1.9994e-01, -2.1569e-01],\n",
       "                        [-1.6075e-01, -2.8695e-01, -5.8013e-02]],\n",
       "              \n",
       "                       [[ 5.9462e-02, -1.6738e-01, -5.0169e-02],\n",
       "                        [-3.9482e-01, -1.5779e-01, -2.7953e-01],\n",
       "                        [-1.1422e-01, -8.5211e-02, -2.1426e-01]],\n",
       "              \n",
       "                       [[ 7.5473e-01,  6.0184e-01,  8.3161e-01],\n",
       "                        [ 1.1422e-01, -1.8447e-01,  1.0666e-01],\n",
       "                        [-7.5366e-02, -2.2622e-01, -2.4511e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.6038e-01, -2.1161e-01, -5.7846e-01],\n",
       "                        [ 1.5329e-01, -2.3119e-02,  9.8431e-02],\n",
       "                        [ 8.9221e-03, -1.2270e-01, -6.4404e-02]],\n",
       "              \n",
       "                       [[ 3.8742e-02,  1.1594e-01, -6.9395e-02],\n",
       "                        [-2.8372e-01, -2.6397e-01, -4.1418e-01],\n",
       "                        [-3.7714e-01, -1.2823e-02, -1.1631e-01]],\n",
       "              \n",
       "                       [[ 1.1880e+00,  1.1930e+00,  9.8560e-02],\n",
       "                        [-1.3237e-01,  3.7566e-03, -2.6210e-01],\n",
       "                        [-1.1007e-01,  1.0947e-01, -2.9152e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.1079e-01,  5.9509e-01,  6.1701e-01],\n",
       "                        [ 5.3335e-03, -1.8511e-01, -1.7860e-01],\n",
       "                        [-1.8816e-01, -3.1641e-01, -1.7504e-01]],\n",
       "              \n",
       "                       [[ 1.3819e-01,  8.2587e-02, -5.1743e-02],\n",
       "                        [-2.1130e-01,  3.3379e-03,  1.2364e-01],\n",
       "                        [-2.1864e-01,  4.4949e-02,  1.4755e-01]],\n",
       "              \n",
       "                       [[ 5.4183e-01,  3.5040e-01,  5.2296e-01],\n",
       "                        [-4.0994e-02, -3.6869e-02, -1.1729e-01],\n",
       "                        [-4.7622e-02, -1.0110e-01,  5.0220e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2562e+00, -5.1695e-01, -5.4463e-01],\n",
       "                        [-1.4977e-01,  3.7312e-01,  3.5898e-01],\n",
       "                        [-5.7635e-02,  2.5530e-01,  1.9801e-02]],\n",
       "              \n",
       "                       [[-1.2025e-01, -9.1862e-03, -2.9350e-02],\n",
       "                        [-2.9931e-02,  3.7165e-02, -2.9381e-01],\n",
       "                        [-7.2904e-02, -1.2755e-04, -2.5069e-01]],\n",
       "              \n",
       "                       [[ 1.2933e+00,  2.2547e-01,  1.6145e-01],\n",
       "                        [ 5.3685e-02, -7.3240e-01, -6.6061e-01],\n",
       "                        [ 9.8510e-02, -3.1277e-01, -4.3029e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.0592e-01,  2.3618e-01,  1.9810e-01],\n",
       "                        [ 2.6806e-01,  3.3558e-01,  2.4782e-01],\n",
       "                        [ 7.6681e-03,  1.1999e-01,  3.6645e-01]],\n",
       "              \n",
       "                       [[-6.0606e-02, -7.5211e-02, -1.3191e-01],\n",
       "                        [-2.6569e-01, -3.9604e-02, -5.1132e-01],\n",
       "                        [-3.1173e-01, -1.2551e-01, -3.5287e-01]],\n",
       "              \n",
       "                       [[ 2.1267e-01,  7.6462e-02,  1.9866e-01],\n",
       "                        [-2.2475e-01, -1.2461e-01, -1.3642e-01],\n",
       "                        [-2.4759e-01, -7.8837e-02, -3.8262e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.6925e-01, -5.1704e-01, -5.0606e-01],\n",
       "                        [-3.8338e-02,  8.5570e-02,  1.1413e-01],\n",
       "                        [ 1.0592e-01,  1.1452e-04,  1.6263e-02]],\n",
       "              \n",
       "                       [[-1.2828e-01,  6.9789e-02, -1.6735e-01],\n",
       "                        [-1.0457e-01, -1.3808e-01, -1.2171e-01],\n",
       "                        [-1.5279e-01, -7.3754e-02, -1.1857e-01]],\n",
       "              \n",
       "                       [[ 4.7458e-01,  3.6411e-01, -1.1734e-01],\n",
       "                        [ 1.2828e-01, -2.1956e-01, -1.9975e-01],\n",
       "                        [ 7.9289e-02, -1.2267e-01, -3.9434e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1405e-01,  7.5372e-01,  1.5119e-01],\n",
       "                        [-1.2427e-01,  7.3846e-01, -1.0879e-01],\n",
       "                        [-3.5104e-01,  7.0848e-01, -5.0925e-02]],\n",
       "              \n",
       "                       [[-1.4964e-01,  4.4625e-01,  1.7950e-01],\n",
       "                        [ 1.4690e-01,  5.8155e-01,  2.5478e-02],\n",
       "                        [-1.2546e-01,  5.6202e-01,  2.1246e-01]],\n",
       "              \n",
       "                       [[-5.2109e-01,  5.8635e-02,  1.1113e-01],\n",
       "                        [-1.1420e-01,  2.5816e-01, -4.4685e-01],\n",
       "                        [-3.8650e-03,  2.6576e-01, -5.2771e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.4286e-02, -2.0979e-01, -2.7301e-01],\n",
       "                        [-1.3272e-01, -2.3866e-01,  6.8587e-02],\n",
       "                        [-8.9939e-02, -1.1872e-01, -3.2601e-01]],\n",
       "              \n",
       "                       [[ 2.5360e-02,  1.5102e-01, -8.5913e-02],\n",
       "                        [-2.4582e-01, -1.6043e-01, -2.1860e-01],\n",
       "                        [-3.6291e-02, -2.9341e-01, -2.9064e-01]],\n",
       "              \n",
       "                       [[-1.1633e-01,  1.0986e-01,  3.4129e-01],\n",
       "                        [-8.7604e-02,  4.9565e-02,  5.6790e-02],\n",
       "                        [-3.1033e-01, -2.2409e-02,  1.2355e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3388e-01,  2.2808e-01,  1.2458e-01],\n",
       "                        [ 6.3411e-01,  3.0096e-01,  4.0213e-01],\n",
       "                        [ 6.8730e-01,  2.3788e-01,  6.0535e-01]],\n",
       "              \n",
       "                       [[ 2.2909e-01,  2.0988e-01,  1.7329e-01],\n",
       "                        [ 4.1316e-02,  1.1609e-01,  1.3966e-01],\n",
       "                        [ 7.8463e-02,  4.4402e-02,  1.6208e-01]],\n",
       "              \n",
       "                       [[ 5.4626e-02, -1.6068e-01, -1.6262e-02],\n",
       "                        [-4.9578e-01, -5.0472e-01, -9.1947e-01],\n",
       "                        [-2.5762e-01, -1.4424e-01, -5.8295e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.3871e-01, -3.1785e-01, -3.8055e-01],\n",
       "                        [-8.7378e-01,  3.6715e-03, -2.0539e-01],\n",
       "                        [-6.5174e-01, -2.7667e-01, -4.7379e-01]],\n",
       "              \n",
       "                       [[ 2.5699e-02,  2.6261e-01,  4.1086e-02],\n",
       "                        [ 3.0922e-01,  2.0929e-01,  2.8442e-03],\n",
       "                        [ 4.8824e-03,  1.3326e-02, -5.5047e-02]],\n",
       "              \n",
       "                       [[-3.8816e-02,  5.6387e-02,  3.4092e-02],\n",
       "                        [-1.8099e-01, -1.1222e-01, -1.9277e-01],\n",
       "                        [-3.7087e-01, -3.1657e-01, -5.2063e-01]]]], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer2_conv1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.0061, -0.0074, -0.0117,  0.0121, -0.0117,  0.0115, -0.0173, -0.0107,\n",
       "                       0.0118,  0.0006,  0.0145, -0.0041, -0.0072,  0.0133,  0.0064, -0.0095,\n",
       "                       0.0507,  0.0065,  0.0085,  0.0024, -0.0009,  0.0035,  0.0272,  0.0301,\n",
       "                      -0.0024, -0.0080, -0.0063,  0.0053, -0.0152, -0.0012, -0.0090, -0.0017,\n",
       "                      -0.0098, -0.0045, -0.0138, -0.0028,  0.0016, -0.0017,  0.0069,  0.0327,\n",
       "                       0.0028, -0.0027, -0.0078, -0.0016,  0.0077, -0.0123,  0.0126,  0.0051,\n",
       "                      -0.0041, -0.0104,  0.0041, -0.0125,  0.0001, -0.0125,  0.0070,  0.0024,\n",
       "                      -0.0084, -0.0086, -0.0096, -0.0108,  0.0058, -0.0054,  0.0065,  0.0097],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer2_bn1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([1.8006, 1.6574, 1.5743, 1.7721, 2.5802, 1.6765, 4.5315, 1.9294, 1.6883,\n",
       "                      1.0903, 1.4664, 1.8486, 1.3674, 2.5583, 2.4709, 2.0229, 4.2057, 1.7229,\n",
       "                      1.7427, 1.8786, 3.3514, 2.8957, 4.5705, 4.3867, 2.5387, 2.4468, 1.3090,\n",
       "                      1.9535, 1.3293, 2.4224, 3.6742, 1.3701, 2.7016, 1.9399, 2.7315, 2.1603,\n",
       "                      2.0396, 1.7325, 2.3534, 4.5764, 1.1270, 1.9707, 2.0453, 4.6860, 2.8860,\n",
       "                      0.9707, 1.8030, 1.0719, 2.4400, 1.8902, 1.4621, 1.7544, 1.9244, 1.8389,\n",
       "                      1.3023, 0.8515, 1.7570, 2.7085, 2.7378, 1.2837, 1.8292, 2.5524, 1.2722,\n",
       "                      2.8582], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer2_bn1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 2.5620,  0.5770,  0.1226,  0.7932,  0.6382,  0.5190,  2.1683, -0.5554,\n",
       "                      -0.8415, -0.2209,  1.0965,  1.6734,  0.4043,  0.3797,  1.0319,  2.2054,\n",
       "                       3.2881,  0.1839,  0.4874,  0.8378,  1.5273,  1.7520,  3.2706,  2.8135,\n",
       "                       0.5714,  1.2412,  0.8437,  0.8481,  0.2792,  0.7743,  1.2257, -0.3633,\n",
       "                       0.5785,  1.5509,  1.1421,  0.5874,  0.3791,  0.7140,  0.5410,  2.1683,\n",
       "                       0.7851,  0.5875,  0.5307,  2.3381,  1.7931, -0.3888,  0.3233, -0.4184,\n",
       "                       0.7976,  0.5345, -0.0385, -0.4130,  0.0148, -0.3207, -0.4653,  0.3066,\n",
       "                      -0.4990,  1.2755, -0.0925,  0.3053, -0.5811,  0.2498, -0.4664,  0.5641],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer2_bn1.running_mean',\n",
       "              tensor([-0.3606, -0.1986, -0.2730, -0.8755, -0.6179,  0.7987,  1.0269, -0.0453,\n",
       "                      -1.6316,  0.3216, -0.7697, -2.0795,  1.3095,  0.5881,  0.1942, -0.9691,\n",
       "                      -0.3029,  2.1412,  0.4119,  0.5415,  1.1922, -0.1577, -0.0518,  1.4803,\n",
       "                       0.3954,  0.9923, -0.7731,  0.3060, -1.7908,  0.5858, -1.5118, -0.4015,\n",
       "                       1.0989, -1.0380,  0.9151,  0.8465, -0.8467,  0.4076,  0.1113,  1.3063,\n",
       "                      -0.7957,  1.3055, -0.2324,  1.9965,  1.2630, -0.1089, -0.6873, -0.2189,\n",
       "                      -0.1530, -2.1985,  0.2707,  0.3281, -0.5259, -0.1308, -0.7205, -4.4666,\n",
       "                      -2.0623, -0.1700, -0.4238, -0.0434, -2.1344,  0.5428, -1.0470,  1.3917],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layer2_bn1.running_var',\n",
       "              tensor([2.4251, 2.5781, 3.4167, 2.8160, 2.9843, 3.5000, 6.6006, 2.3422, 1.8148,\n",
       "                      6.3011, 6.5257, 3.9715, 3.7955, 2.4123, 2.4387, 4.0073, 2.8801, 2.1592,\n",
       "                      2.4377, 4.1775, 2.7095, 3.4276, 6.0370, 9.3577, 2.2173, 2.4557, 2.0820,\n",
       "                      2.2656, 3.4541, 1.9954, 1.8248, 2.7145, 2.9376, 3.0470, 2.3419, 2.0789,\n",
       "                      5.4497, 3.2750, 3.1555, 5.2143, 2.0486, 2.4958, 3.0094, 8.1939, 3.0690,\n",
       "                      3.5244, 4.2608, 3.9720, 2.6836, 3.0020, 6.0987, 2.3896, 5.1029, 5.3273,\n",
       "                      2.8751, 4.3656, 2.4400, 3.3942, 3.3170, 4.8016, 2.5401, 4.3643, 2.8004,\n",
       "                      5.8383], device='cuda:0')),\n",
       "             ('module.layer2_bn1.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.layer2_conv2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[-5.3924e-01, -4.3894e-01, -4.4764e-01],\n",
       "                        [ 1.0580e-01,  1.8948e-01,  2.3411e-01],\n",
       "                        [ 2.3522e-01,  4.3981e-01,  2.6377e-01]],\n",
       "              \n",
       "                       [[ 3.4067e-01, -1.4604e-01,  1.9183e-01],\n",
       "                        [-1.9455e-01, -3.3358e-01, -3.1329e-01],\n",
       "                        [ 1.2150e-02,  2.6955e-01, -3.1871e-02]],\n",
       "              \n",
       "                       [[ 5.3832e-01, -1.7542e-02,  1.6898e-01],\n",
       "                        [ 2.9494e-02, -1.4759e-01, -7.1086e-02],\n",
       "                        [-3.2818e-01, -2.6995e-01, -3.3254e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.0414e-01,  1.6955e-01,  4.9156e-01],\n",
       "                        [-1.2349e-01, -1.8178e-01, -1.3555e-01],\n",
       "                        [-4.2676e-01, -3.0347e-01, -4.6895e-01]],\n",
       "              \n",
       "                       [[-3.2382e-01, -1.8986e-02,  1.0260e-01],\n",
       "                        [-1.5996e-01,  1.3683e-01,  3.1044e-01],\n",
       "                        [-3.1216e-01, -4.5033e-02,  8.0417e-02]],\n",
       "              \n",
       "                       [[ 2.4971e-01,  1.4263e-01,  2.6013e-01],\n",
       "                        [-4.1013e-02, -2.0508e-02,  6.0567e-02],\n",
       "                        [-4.6869e-01, -3.8618e-01, -5.1788e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5495e-01, -3.2158e-02,  7.1668e-02],\n",
       "                        [-1.2357e-01, -1.8606e-01, -3.1248e-01],\n",
       "                        [-5.2468e-02, -8.5380e-02, -1.4971e-01]],\n",
       "              \n",
       "                       [[ 3.2614e-01,  7.6441e-02,  1.5928e-01],\n",
       "                        [ 4.0400e-02, -3.1909e-02,  8.2598e-03],\n",
       "                        [-2.1724e-01, -1.9990e-01, -1.8631e-01]],\n",
       "              \n",
       "                       [[ 3.7148e-01,  1.5364e-01,  1.5544e-01],\n",
       "                        [ 6.7325e-02, -7.7538e-02, -1.3540e-01],\n",
       "                        [ 1.9158e-03, -7.1461e-02,  2.6819e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3595e-01, -3.1518e-02,  3.6867e-01],\n",
       "                        [-1.5096e-01, -2.2706e-01,  5.3189e-02],\n",
       "                        [-1.3580e-01, -1.1117e-01,  4.3971e-01]],\n",
       "              \n",
       "                       [[-4.2283e-01,  6.2436e-02,  2.9201e-01],\n",
       "                        [-6.6437e-01, -5.0497e-02,  2.4606e-01],\n",
       "                        [-4.2589e-01,  5.5928e-02,  3.0933e-01]],\n",
       "              \n",
       "                       [[ 8.1887e-02,  7.2937e-02,  4.4774e-01],\n",
       "                        [ 3.4714e-02, -1.0020e-01,  2.2808e-01],\n",
       "                        [ 1.5410e-01,  1.8057e-01,  1.2158e+00]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1570e-01, -4.4310e-02,  1.4351e-01],\n",
       "                        [-2.3552e-01, -1.6753e-01, -4.8556e-02],\n",
       "                        [-1.7855e-01, -4.0755e-02,  1.1300e-01]],\n",
       "              \n",
       "                       [[-5.0996e-01,  1.9849e-01,  1.6244e-01],\n",
       "                        [-3.2855e-01,  1.8485e-01,  1.7628e-01],\n",
       "                        [-2.8173e-01,  1.9045e-01,  1.1502e-01]],\n",
       "              \n",
       "                       [[-4.7990e-01,  6.0613e-02,  7.6245e-02],\n",
       "                        [-2.2205e-01, -2.4181e-02, -5.3619e-02],\n",
       "                        [-1.0572e-01,  1.1122e-01,  1.0081e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.4491e-01, -4.4307e-02,  1.5424e-01],\n",
       "                        [-3.7534e-01, -5.6459e-02,  2.9270e-02],\n",
       "                        [-2.8953e-01,  9.1063e-02,  1.9061e-01]],\n",
       "              \n",
       "                       [[ 1.7522e+00,  2.4135e-02, -8.2886e-01],\n",
       "                        [ 1.9152e+00,  8.0063e-02, -8.6623e-01],\n",
       "                        [ 1.8265e+00,  6.4283e-02, -6.3492e-01]],\n",
       "              \n",
       "                       [[ 3.6902e-01, -8.4614e-02, -4.3729e-02],\n",
       "                        [ 4.0071e-01, -5.1864e-02, -8.0913e-02],\n",
       "                        [ 3.8098e-01,  5.2569e-02,  3.2648e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5091e-01,  1.4848e-01, -1.6841e-01],\n",
       "                        [ 2.5609e-01, -3.3689e-02, -5.9802e-01],\n",
       "                        [ 1.7846e-01, -2.1902e-01, -8.1675e-01]],\n",
       "              \n",
       "                       [[ 3.2916e-01,  1.3999e-01, -2.1513e-01],\n",
       "                        [ 2.0360e-01,  1.1579e-01,  3.4927e-02],\n",
       "                        [ 6.6356e-03, -8.2755e-03, -1.0946e-01]],\n",
       "              \n",
       "                       [[ 1.5968e-01,  7.3216e-02, -9.6027e-02],\n",
       "                        [ 7.4631e-02,  1.3519e-01,  2.3549e-01],\n",
       "                        [ 2.1455e-02,  1.2328e-01,  1.9731e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4703e-01,  1.1428e-01, -4.2051e-01],\n",
       "                        [ 2.8848e-03,  6.9384e-02, -1.4156e-01],\n",
       "                        [ 1.1673e-01,  1.9482e-01, -3.7630e-01]],\n",
       "              \n",
       "                       [[ 1.0523e-01,  5.7257e-02,  8.1501e-02],\n",
       "                        [ 8.8547e-02, -4.0336e-02, -2.3752e-02],\n",
       "                        [ 5.1419e-02, -5.7857e-02, -7.1430e-03]],\n",
       "              \n",
       "                       [[ 3.5425e-01,  2.6117e-01,  2.6017e-01],\n",
       "                        [ 3.0300e-01,  3.0600e-01,  2.6242e-01],\n",
       "                        [ 3.4406e-01,  3.6254e-01,  8.4355e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9141e-01, -3.9216e-01, -1.9949e-01],\n",
       "                        [ 5.2006e-01,  2.9085e-01,  2.9029e-01],\n",
       "                        [-4.0424e-02, -1.9898e-01, -6.2582e-02]],\n",
       "              \n",
       "                       [[ 5.3617e-01,  1.7412e-01,  3.5110e-01],\n",
       "                        [ 5.6687e-02, -2.4740e-01, -9.8567e-02],\n",
       "                        [ 2.8030e-01, -7.0793e-02,  1.3463e-01]],\n",
       "              \n",
       "                       [[ 7.4419e-01,  3.8731e-01,  3.9541e-01],\n",
       "                        [-3.1870e-02, -3.4756e-01, -3.9869e-01],\n",
       "                        [ 2.2280e-01,  1.3900e-01,  1.1659e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.1645e-01,  2.3390e-01,  5.4753e-01],\n",
       "                        [-2.2353e-01, -3.8494e-01, -2.3749e-01],\n",
       "                        [ 4.6457e-01,  3.5886e-01,  5.3694e-01]],\n",
       "              \n",
       "                       [[-3.7903e-01, -8.9724e-02, -5.5884e-02],\n",
       "                        [-4.4664e-01, -1.6726e-01, -1.8352e-01],\n",
       "                        [ 2.1002e-02,  1.8189e-01,  1.8622e-01]],\n",
       "              \n",
       "                       [[ 1.1553e-03, -2.6234e-01, -7.4962e-02],\n",
       "                        [-3.8364e-01, -5.6703e-01, -3.5341e-01],\n",
       "                        [ 2.5696e-01,  2.0547e-01,  5.0397e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7546e-01, -5.2521e-02,  7.5680e-02],\n",
       "                        [-3.7038e-01, -1.6289e-01,  1.6601e-02],\n",
       "                        [-1.8997e-01,  1.7283e-02,  5.0940e-02]],\n",
       "              \n",
       "                       [[-3.5611e-01, -6.8387e-02, -4.4147e-01],\n",
       "                        [ 1.7785e-01,  2.1876e-01,  2.1294e-02],\n",
       "                        [ 4.4837e-02,  8.5949e-02, -2.1533e-02]],\n",
       "              \n",
       "                       [[-2.5292e-01, -7.8222e-03, -2.1232e-01],\n",
       "                        [ 1.1560e-01,  1.6936e-01,  4.1908e-02],\n",
       "                        [-2.1196e-02, -1.0694e-02, -7.9052e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3792e-01, -5.8649e-02, -4.4248e-01],\n",
       "                        [ 2.1833e-02,  1.1867e-01, -3.8020e-02],\n",
       "                        [-7.5459e-02, -1.3278e-03, -3.4959e-02]],\n",
       "              \n",
       "                       [[-3.8203e-01,  3.0904e-01,  3.0120e-01],\n",
       "                        [-4.3242e-01,  2.6762e-01,  2.6589e-01],\n",
       "                        [-5.0041e-01,  1.6891e-01,  1.6658e-01]],\n",
       "              \n",
       "                       [[ 2.2279e-01,  3.2433e-01,  1.4425e-01],\n",
       "                        [ 2.7189e-01,  3.7918e-01,  2.8928e-01],\n",
       "                        [ 3.1426e-01,  3.6066e-01,  2.2762e-01]]]], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer2_conv2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-9.9821e-03, -1.2010e-03,  3.6814e-03, -6.6714e-03, -4.7429e-03,\n",
       "                      -5.9464e-05,  2.0744e-04,  2.1682e-03, -4.0752e-03,  8.3441e-04,\n",
       "                      -8.5757e-03,  6.5615e-03,  5.9774e-03,  4.9094e-03,  6.0104e-03,\n",
       "                      -1.3920e-03,  7.0858e-03, -2.3930e-03, -8.8489e-03,  8.9671e-04,\n",
       "                       6.8176e-03, -1.7966e-03,  2.7505e-03, -5.9619e-03, -8.7840e-03,\n",
       "                      -5.7762e-03, -2.8521e-03,  3.2410e-03, -8.9637e-03,  6.1997e-03,\n",
       "                       8.1409e-03,  1.5945e-03, -3.6750e-03, -6.4256e-05, -6.2440e-03,\n",
       "                      -5.1278e-03,  3.2510e-03, -2.0159e-03, -6.5039e-03, -7.1555e-03,\n",
       "                      -5.8678e-03,  6.2565e-03, -1.5214e-03,  2.2033e-04, -2.4321e-04,\n",
       "                      -4.6728e-03,  7.7164e-03,  9.3125e-03,  7.3476e-03,  2.7672e-03,\n",
       "                      -8.8588e-05,  5.9077e-03,  6.3666e-03, -8.6734e-03, -2.6129e-03,\n",
       "                      -9.8572e-03, -7.6833e-03,  8.1874e-03,  3.4656e-04, -6.7296e-04,\n",
       "                       2.0139e-04, -7.2137e-03, -9.2903e-03, -2.5044e-03], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer2_bn2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.8666,  0.5506,  0.5808,  0.3413,  0.3030,  0.7690,  0.2738,  0.2786,\n",
       "                       0.4153,  0.2186,  0.3474,  0.5731,  0.3187,  0.4592,  0.1904,  0.0104,\n",
       "                       0.3027,  0.1927,  0.4295,  0.3215,  0.3026,  0.4871,  0.2304,  0.3437,\n",
       "                       0.3505,  0.3880,  0.3831,  0.2706,  0.2288, -0.0030,  0.2970,  0.3604,\n",
       "                       0.4092,  0.6261,  0.2324,  0.2568,  0.5885,  0.2119,  0.2102,  0.2947,\n",
       "                       0.3628,  0.3694,  0.2316,  0.3008,  0.2927,  0.3508,  0.2465,  0.2068,\n",
       "                       0.3121,  0.5409,  0.0848,  0.2920,  0.4236,  0.4385,  0.3047,  0.4944,\n",
       "                       0.0051,  0.0939,  0.2674,  0.2980,  0.5630,  0.4357,  0.3226,  0.3486],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer2_bn2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.1071, -0.1576, -0.4300, -0.3431, -0.5436,  0.1266,  0.0364, -0.2133,\n",
       "                      -0.1225, -0.4065, -0.4035, -0.4752, -0.0614,  0.2146, -0.2734, -0.1352,\n",
       "                      -0.2553,  0.1705, -0.3781, -0.1338, -0.2591, -0.0827, -0.3375, -0.0168,\n",
       "                      -0.4270, -0.2715,  0.0792,  0.1396,  0.0675, -0.1245,  0.2357, -0.2828,\n",
       "                       0.1496, -0.2697,  0.0276, -0.3898, -0.3206, -0.0392, -0.2203, -0.2981,\n",
       "                       0.2927, -0.0768, -0.3090, -0.0242, -0.3390,  0.0330, -0.3696, -0.3807,\n",
       "                      -0.1809, -0.4516, -0.0030, -0.3712, -0.4426, -0.0883,  0.1708, -0.0373,\n",
       "                      -0.0232,  0.0521,  0.1314, -0.3923, -0.3826,  0.0421, -0.4120, -0.1409],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer2_bn2.running_mean',\n",
       "              tensor([  69.0810,  -74.6542,  -78.8880,   71.3498,   44.9299,  -14.0191,\n",
       "                        46.6521,  -11.6198,   51.7675, -160.9355,   20.9090,   42.9653,\n",
       "                         6.6807,   78.7373,  -63.3337,  -27.9240,  -11.5486,  171.7829,\n",
       "                       -39.9677,   71.1763,  -71.4721,   39.9337, -187.2262,  113.7926,\n",
       "                       126.9646,    7.7052,  -11.8998,   27.0073,  -16.6117,   37.9912,\n",
       "                       213.0644,  -97.5133,   32.8016,   71.0846,   19.9810, -132.5671,\n",
       "                       -24.3598,  -85.4841,  -61.0181,  -98.6447,   32.7473,  -70.9604,\n",
       "                      -145.6829,  100.1806,  -31.6757,  107.7399,   22.1085,   -7.6763,\n",
       "                      -201.8341, -116.5182,  128.7484,   66.7469,   10.0283,    6.0050,\n",
       "                       147.6793,   86.6103,  -11.8181,   45.8133,    8.9638,   61.1750,\n",
       "                       -65.6568,   26.4680,   98.0194,  133.2740], device='cuda:0')),\n",
       "             ('module.layer2_bn2.running_var',\n",
       "              tensor([ 2553.7178,  7908.6074,  2918.1533,  2501.6382,  2887.5942,  1959.0490,\n",
       "                       3202.1501,  3132.2700,  1976.1079,  3183.9521,  6119.7017,  1977.4513,\n",
       "                       9540.9385,  9555.8477,  9055.8789,   441.8393,  3869.0911,  9053.5498,\n",
       "                       4558.1719,  1898.8125,  4906.9087,  2003.2466,  5349.9282,  3986.5994,\n",
       "                       3148.7407,  2530.9602,  9074.2676,  9636.6855,  5647.4780,  1554.6941,\n",
       "                       6762.9810,  5043.2524,  1175.5588,  2360.2383,  2522.5649,  6999.2134,\n",
       "                       3541.7688, 10195.5332,  3698.2771,  4270.1904,  2104.6475,  5087.9824,\n",
       "                       8049.2324,  3193.2729,  3701.9583,  3091.4910,  2595.0049,  6823.9272,\n",
       "                      10879.8477,  1753.7808,  5281.2510,  3528.1335,  2557.6914,  9050.7275,\n",
       "                       6474.9170,  3208.3174,  1173.9037,  2956.9968,  3955.2942,  3796.5806,\n",
       "                       1856.2968,  2803.4458,  5006.5029,  3432.0967], device='cuda:0')),\n",
       "             ('module.layer2_bn2.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.layer3_conv1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[-7.1036e-02,  1.1997e-01,  5.6973e-02],\n",
       "                        [-2.9530e-01, -8.9347e-03, -1.8832e-01],\n",
       "                        [-3.9521e-01, -1.4565e-01, -6.8207e-01]],\n",
       "              \n",
       "                       [[ 9.2326e-02, -1.3455e-01, -1.4939e-01],\n",
       "                        [ 1.3084e-01, -1.3881e-01,  1.2554e-01],\n",
       "                        [ 7.4873e-02, -1.2702e-01,  8.8510e-01]],\n",
       "              \n",
       "                       [[ 1.8565e-01, -2.3793e-02, -3.8833e-01],\n",
       "                        [ 1.3293e-01, -6.3884e-02, -4.3457e-01],\n",
       "                        [ 1.1126e-01, -1.0946e-01, -4.8106e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5872e-02,  1.0998e-01, -2.6712e-01],\n",
       "                        [ 5.5057e-02,  2.4387e-01, -2.3333e-01],\n",
       "                        [ 1.2274e-01,  6.3111e-02, -1.0177e+00]],\n",
       "              \n",
       "                       [[-1.8609e-01, -1.7778e-01, -1.9586e-01],\n",
       "                        [-1.5401e-01, -1.8379e-01, -1.2130e-01],\n",
       "                        [ 1.0214e-01,  4.8704e-02,  3.4544e-01]],\n",
       "              \n",
       "                       [[-4.9029e-01, -9.1712e-02, -7.2361e-01],\n",
       "                        [-2.9953e-01,  1.5805e-01, -2.1429e-01],\n",
       "                        [-2.9340e-01,  1.9318e-01, -5.3612e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1676e-01,  4.7470e-01,  6.4688e-01],\n",
       "                        [ 1.0100e-01, -1.1171e-01, -8.1246e-02],\n",
       "                        [ 5.3951e-01,  3.4966e-01,  4.0888e-01]],\n",
       "              \n",
       "                       [[-7.2614e-02, -8.1334e-02,  5.8120e-01],\n",
       "                        [-1.0944e-01, -2.0572e-01,  1.4672e-01],\n",
       "                        [ 4.6120e-02, -2.1574e-01, -1.6380e-01]],\n",
       "              \n",
       "                       [[ 6.6493e-02,  1.8260e-01,  4.6289e-02],\n",
       "                        [ 7.9727e-02,  1.5806e-01, -1.0132e-01],\n",
       "                        [ 5.0001e-02,  1.7398e-01, -4.8142e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.6366e-01,  1.9436e-02, -5.1694e-01],\n",
       "                        [ 2.0622e-03, -1.2678e-02, -4.2593e-01],\n",
       "                        [ 7.3349e-02,  2.9371e-02, -1.0458e-01]],\n",
       "              \n",
       "                       [[ 1.9271e-01,  2.7775e-01,  5.6914e-01],\n",
       "                        [ 2.9175e-01,  2.0435e-01,  2.4776e-01],\n",
       "                        [-1.1014e-01, -2.2047e-01, -1.8814e-01]],\n",
       "              \n",
       "                       [[ 5.0780e-01,  1.9240e-01,  2.9552e-02],\n",
       "                        [ 3.3293e-02, -6.8937e-02, -2.9548e-01],\n",
       "                        [ 8.6625e-02,  2.5789e-01, -7.0066e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1204e-01, -9.6732e-02, -2.7224e-01],\n",
       "                        [-1.3805e-02,  1.1073e-01,  1.2904e-02],\n",
       "                        [-4.0324e-01, -5.7219e-01, -7.4450e-01]],\n",
       "              \n",
       "                       [[-8.2728e-01, -1.4200e-01, -1.9818e-01],\n",
       "                        [-5.5957e-01, -8.2050e-02, -3.1659e-01],\n",
       "                        [-6.4379e-01, -1.3383e-01, -5.1239e-01]],\n",
       "              \n",
       "                       [[ 3.1764e-01, -1.4882e-01, -2.0644e-01],\n",
       "                        [ 2.7617e-01, -1.6421e-01, -3.2650e-01],\n",
       "                        [ 4.4220e-01, -1.1433e-01, -2.9941e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.5456e-02, -4.4485e-02,  3.4412e-01],\n",
       "                        [ 1.0812e-01, -9.2546e-02,  3.0544e-01],\n",
       "                        [ 4.4080e-01,  6.8239e-02,  7.3436e-01]],\n",
       "              \n",
       "                       [[ 6.2147e-01,  5.2403e-01,  4.0310e-01],\n",
       "                        [ 3.2503e-01,  8.2296e-02, -1.9247e-02],\n",
       "                        [ 3.9475e-01,  1.2127e-01,  1.5824e-01]],\n",
       "              \n",
       "                       [[ 5.5492e-01,  3.2003e-01,  2.4919e-01],\n",
       "                        [ 1.9281e-01,  1.4261e-01,  1.0660e-01],\n",
       "                        [ 3.0308e-01,  3.1435e-01,  2.2395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2858e-01, -1.5485e-01, -8.6671e-01],\n",
       "                        [ 1.7719e-01, -1.8744e-02, -1.1323e-01],\n",
       "                        [ 1.1353e-01, -3.7942e-02,  1.2968e-01]],\n",
       "              \n",
       "                       [[-1.9665e-02, -2.8793e-02, -5.1722e-01],\n",
       "                        [ 5.0226e-02,  1.8484e-01, -2.6724e-01],\n",
       "                        [-7.0083e-03,  1.2885e-01, -4.8398e-01]],\n",
       "              \n",
       "                       [[-1.2939e+00, -5.4235e-01, -2.5960e-01],\n",
       "                        [-1.3269e+00, -5.3277e-01, -2.6781e-01],\n",
       "                        [-1.1329e+00, -4.1995e-01, -1.3059e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0000e-02,  2.1283e-01,  6.6072e-01],\n",
       "                        [ 3.3468e-02, -4.5314e-02,  3.0752e-01],\n",
       "                        [-2.3090e-02, -7.5716e-02,  7.7573e-01]],\n",
       "              \n",
       "                       [[-4.2773e-01, -1.3186e-01,  4.0264e-01],\n",
       "                        [-4.6953e-01, -2.7595e-01, -8.6674e-02],\n",
       "                        [-2.5442e-01, -2.8971e-01, -4.3627e-01]],\n",
       "              \n",
       "                       [[-9.0300e-02, -7.1958e-02,  5.7773e-01],\n",
       "                        [-1.2032e-01, -1.5267e-01,  1.6759e-01],\n",
       "                        [-8.8631e-05, -5.7260e-02,  5.7117e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3655e-01, -2.7782e-02,  6.1563e-01],\n",
       "                        [-4.4041e-01, -3.0877e-01, -5.8588e-02],\n",
       "                        [-4.7780e-01, -3.2820e-01, -4.3087e-01]],\n",
       "              \n",
       "                       [[ 1.4689e-01,  6.6479e-03,  1.0318e+00],\n",
       "                        [-8.2926e-02, -2.9388e-01,  3.1205e-01],\n",
       "                        [ 1.8661e-01, -1.2235e-01,  6.6525e-01]],\n",
       "              \n",
       "                       [[-8.3370e-01, -2.1584e-01,  2.0245e-01],\n",
       "                        [-9.7733e-01, -3.2777e-01,  1.7606e-01],\n",
       "                        [-8.7560e-01, -1.8478e-01,  3.2516e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0356e-01,  2.3745e-01, -4.0836e-01],\n",
       "                        [ 1.0334e-01,  3.6689e-01, -3.0544e-01],\n",
       "                        [ 1.6377e-01,  4.7221e-01, -7.3578e-01]],\n",
       "              \n",
       "                       [[-8.2984e-02,  6.2361e-02,  6.4322e-01],\n",
       "                        [-2.9133e-01, -2.7206e-01,  8.3905e-02],\n",
       "                        [ 5.4386e-01,  3.4761e-01,  6.2643e-01]],\n",
       "              \n",
       "                       [[ 2.5952e-01,  3.3144e-02, -2.2109e-01],\n",
       "                        [ 3.5192e-01,  1.5275e-01,  2.4881e-02],\n",
       "                        [ 1.8879e-01, -8.0341e-04, -1.9703e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.5904e-01,  1.1577e-01,  4.4100e-01],\n",
       "                        [ 2.4931e-01, -3.8850e-02,  1.0281e-01],\n",
       "                        [ 4.7655e-01,  3.1075e-02,  1.2064e-01]],\n",
       "              \n",
       "                       [[ 2.6239e-01,  2.2336e-02, -7.9026e-02],\n",
       "                        [ 3.1227e-01,  1.5502e-01,  1.2044e-02],\n",
       "                        [ 1.3614e-01,  2.6532e-02, -4.6841e-01]],\n",
       "              \n",
       "                       [[-3.9816e-01, -3.5613e-01, -5.1467e-02],\n",
       "                        [-3.0952e-01, -1.5849e-01,  1.1787e-01],\n",
       "                        [-3.5576e-01, -2.3599e-01,  5.9801e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0718e-01,  1.4284e-01, -7.0730e-02],\n",
       "                        [-1.8414e-01, -7.0811e-03, -1.3990e-01],\n",
       "                        [-3.8125e-02, -3.9160e-02,  1.5435e-01]],\n",
       "              \n",
       "                       [[ 1.7865e-01,  1.2546e-01, -8.7191e-02],\n",
       "                        [-1.1653e-02,  2.3612e-01,  9.7040e-02],\n",
       "                        [-6.2887e-01, -1.7947e-01, -3.5852e-01]],\n",
       "              \n",
       "                       [[-4.2080e-01, -3.2877e-01, -4.2954e-01],\n",
       "                        [-1.9845e-01, -9.4872e-02, -2.4134e-02],\n",
       "                        [-2.0354e-01, -7.6897e-02,  1.6026e-01]]]], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer3_conv1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.0098,  0.0040,  0.0035, -0.0041, -0.0100, -0.0019,  0.0068,  0.0049,\n",
       "                       0.0075,  0.0075, -0.0064, -0.0083, -0.0064,  0.0113,  0.0080, -0.0039,\n",
       "                       0.0051,  0.0028,  0.0042,  0.0039, -0.0001,  0.0046, -0.0015,  0.0038,\n",
       "                       0.0004,  0.0048, -0.0004, -0.0002,  0.0108,  0.0096, -0.0030,  0.0054,\n",
       "                       0.0048, -0.0014, -0.0037,  0.0041, -0.0107,  0.0049,  0.0110,  0.0065,\n",
       "                       0.0059,  0.0009, -0.0061, -0.0043, -0.0001,  0.0071,  0.0051,  0.0046,\n",
       "                       0.0029,  0.0022,  0.0085,  0.0037,  0.0004,  0.0061, -0.0056,  0.0041,\n",
       "                      -0.0094,  0.0047,  0.0030, -0.0018,  0.0052,  0.0056, -0.0033, -0.0016,\n",
       "                       0.0088, -0.0070,  0.0009, -0.0045,  0.0101, -0.0093,  0.0004, -0.0015,\n",
       "                       0.0023,  0.0085,  0.0093,  0.0032, -0.0048,  0.0022,  0.0008,  0.0068,\n",
       "                       0.0032, -0.0042, -0.0015, -0.0065,  0.0027, -0.0039, -0.0060,  0.0005,\n",
       "                      -0.0048,  0.0041, -0.0087,  0.0016,  0.0036, -0.0043,  0.0043,  0.0099,\n",
       "                      -0.0137, -0.0076,  0.0050, -0.0049,  0.0139,  0.0068, -0.0005,  0.0066,\n",
       "                       0.0027,  0.0055, -0.0046,  0.0050, -0.0058,  0.0067, -0.0063, -0.0068,\n",
       "                      -0.0071,  0.0028, -0.0019,  0.0025, -0.0015,  0.0009,  0.0074, -0.0236,\n",
       "                       0.0020, -0.0083,  0.0072,  0.0074, -0.0029,  0.0069,  0.0017,  0.0114],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer3_bn1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([2.9507, 1.7227, 3.6329, 1.5118, 3.5115, 2.9408, 3.6314, 1.0901, 0.8493,\n",
       "                      3.5588, 3.0700, 2.5998, 1.1303, 2.4861, 2.4171, 3.5734, 2.7728, 2.3706,\n",
       "                      2.1921, 3.0587, 3.1209, 1.6538, 1.6846, 3.2217, 2.6314, 3.5823, 1.1245,\n",
       "                      3.8308, 2.0877, 2.9395, 1.5117, 2.2791, 1.7243, 0.9980, 2.4904, 1.9724,\n",
       "                      3.6029, 2.1163, 3.6110, 2.8775, 2.5639, 2.5851, 1.6749, 2.8119, 2.7818,\n",
       "                      2.5850, 2.4066, 1.5787, 2.5283, 3.8629, 2.4538, 2.0227, 2.2239, 1.7374,\n",
       "                      2.5370, 3.0502, 3.6776, 2.7609, 2.1785, 4.0220, 3.6272, 1.2346, 2.7162,\n",
       "                      3.8820, 2.4733, 2.0209, 2.3705, 1.8690, 4.3799, 1.0957, 2.1065, 3.8349,\n",
       "                      2.1225, 1.6774, 3.1010, 2.0702, 2.7873, 2.3892, 4.0313, 3.9346, 2.7277,\n",
       "                      2.4126, 2.9296, 2.5126, 2.0369, 2.9856, 4.1529, 1.6283, 1.3181, 1.4559,\n",
       "                      2.2864, 1.7306, 1.2950, 3.9759, 1.7296, 1.2607, 4.2161, 3.5118, 2.1925,\n",
       "                      1.4060, 3.6043, 3.0484, 2.9309, 2.8240, 2.7828, 1.4918, 1.2242, 1.7544,\n",
       "                      3.2798, 2.6481, 2.9767, 4.1689, 0.9542, 2.9883, 3.2913, 1.6671, 2.4674,\n",
       "                      2.1780, 1.6239, 3.5800, 3.5990, 2.0644, 2.0998, 1.9051, 1.4417, 3.2561,\n",
       "                      2.0584, 3.0249], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer3_bn1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.3461, -0.4367,  0.6545, -0.2250,  1.3637,  0.3563,  0.7176, -0.2431,\n",
       "                       0.1275,  1.9132,  1.3850,  0.7046, -0.1431,  0.5346,  0.4523,  1.0708,\n",
       "                       0.3846, -0.0169, -0.6185,  0.8798,  0.8222, -0.0676,  0.0874,  1.0506,\n",
       "                       0.5872,  0.9153, -0.5010,  0.6523,  0.8478,  0.7582, -0.1672,  0.1364,\n",
       "                       0.2837,  0.1595,  0.1982,  0.6474,  0.7490, -0.1745,  0.7115, -0.0601,\n",
       "                       0.8475,  0.2064, -0.2480,  0.8117,  0.3025,  0.8234,  0.1506,  0.3130,\n",
       "                      -0.0358,  1.6434,  0.3611, -1.0328,  0.2383,  0.6733,  0.1020,  0.5796,\n",
       "                       0.9371,  0.2919,  0.3450,  1.4519,  0.8722,  0.3021,  1.1384,  1.2111,\n",
       "                      -0.6112,  0.2040,  0.4100, -0.1226,  1.1740, -0.4247,  0.6389,  1.5472,\n",
       "                       1.4971, -0.0679,  1.1374,  0.7966,  1.0106,  0.3438,  1.2510,  1.8252,\n",
       "                       1.0469,  0.6820,  0.4978,  0.9804,  0.0813,  0.6459,  1.0257, -0.1503,\n",
       "                       0.0521,  0.1184,  0.3677,  0.3776,  0.1993,  0.9493,  0.0075, -0.0756,\n",
       "                       0.9051,  1.3915,  0.4657, -0.1668,  1.0433,  0.8839,  0.1355,  0.8864,\n",
       "                       1.0212,  0.2127,  0.1595,  0.0235,  0.6892, -0.5077,  0.9780,  1.5023,\n",
       "                      -0.0480,  0.9533,  0.9501,  0.1316,  1.6808,  0.3883,  0.1102,  0.6178,\n",
       "                       1.2222,  0.2300, -0.1308, -0.3754,  0.1997,  0.7744, -0.0410,  1.1806],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer3_bn1.running_mean',\n",
       "              tensor([ 0.1217,  0.0315, -0.1573,  0.8575,  2.6402,  0.6656,  2.4400, -0.1865,\n",
       "                       0.4373,  0.2115,  1.5405,  1.4959,  0.9300, -0.0850, -0.2121,  2.1065,\n",
       "                       2.4149,  2.2007, -1.5981,  1.3789,  0.5916,  1.0372,  0.7820,  1.5824,\n",
       "                      -0.1663, -0.0452,  1.2042,  1.7574, -0.4875,  1.2800,  1.0097,  1.1179,\n",
       "                       0.3644, -0.9374, -1.5807,  2.1282,  2.3068,  0.9580,  0.3997, -0.7462,\n",
       "                       0.0999,  0.0875,  0.8193,  1.2489, -0.6710,  2.8560, -0.5209, -1.2648,\n",
       "                       0.2012,  0.0325,  1.4453, -0.3153,  0.5046, -0.1693,  2.0260,  1.0061,\n",
       "                       0.9968,  0.4455,  0.1844,  2.5901, -0.8128,  2.1001,  1.4755,  3.5772,\n",
       "                       0.2350, -0.0811, -0.0388, -0.3572,  1.5060, -2.0949,  1.7982, -0.0373,\n",
       "                       0.3946,  0.1043,  2.5654, -0.1977,  2.6649, -1.0897,  0.6796,  1.7591,\n",
       "                       1.7566,  0.0336,  1.6350,  3.8394,  0.5102,  0.4597, -1.6509, -0.5081,\n",
       "                      -0.6695,  1.0310, -9.0697,  0.8068, -1.7710,  0.9965, -1.4575, -2.0287,\n",
       "                       0.8804,  2.3493,  2.5331,  0.8603,  0.8948,  1.6871,  0.3195, -0.0859,\n",
       "                      -0.0598, -0.9166, -0.6225,  0.8866, -1.0224, -1.4129, -0.2287,  0.6982,\n",
       "                      -0.2526,  0.0439,  0.4641, -0.4182,  1.5162,  1.1421, -0.6088,  0.6533,\n",
       "                       0.7042,  0.4411, -0.7714,  1.3643, -0.4074,  1.7588,  1.3313, -0.4075],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layer3_bn1.running_var',\n",
       "              tensor([14.4409,  5.6659, 14.7368,  9.7164, 28.4456, 13.5073, 13.1608, 17.3014,\n",
       "                      35.8586,  6.6039,  4.1399, 11.1000, 19.8197, 11.3518, 11.2318, 31.9073,\n",
       "                      11.3301, 16.0568,  7.4632, 14.5505,  8.4352, 11.0273, 13.6478, 10.5812,\n",
       "                       7.6318, 13.4726, 19.1613, 15.7063, 15.9360, 17.2338, 14.7273, 15.7423,\n",
       "                      12.4587, 24.2189, 13.1878, 22.6364, 22.1713, 15.2116,  8.3607,  9.0104,\n",
       "                       5.2785, 12.5823, 14.6867, 11.3341, 13.3460, 22.8341,  9.4488, 18.4561,\n",
       "                       9.1296,  7.9887, 17.4408,  5.3191, 13.9198, 12.0207, 15.8872,  6.6045,\n",
       "                       6.2344,  9.7907,  7.0466, 17.2500, 10.1356, 26.0175, 16.5074, 22.5062,\n",
       "                       5.6889, 20.1951,  7.1141,  9.2987, 10.6561,  9.6241, 15.0448,  8.5680,\n",
       "                      16.9848, 14.4056, 23.4527, 18.8956, 19.2291,  5.1293, 17.3131,  5.7720,\n",
       "                       5.6806, 19.0497, 20.4441, 28.4799,  9.5997, 22.9627, 11.2624, 10.7011,\n",
       "                      13.9095, 11.3615, 23.4259, 10.6464, 17.3375, 15.5264,  9.0366,  8.2782,\n",
       "                      18.0835, 10.3174, 31.5990, 13.1042,  8.9814, 16.5738,  7.7438, 12.6100,\n",
       "                       6.8297, 15.4359, 12.6161,  9.9234, 10.6001,  8.2021, 12.5325, 13.2578,\n",
       "                      22.1291,  7.2926,  7.7529, 13.1607, 29.0076, 34.3504, 15.5437, 14.3501,\n",
       "                       6.4615, 10.0729,  6.4593, 15.8964, 10.9850, 17.8025, 11.8638, 10.0561],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layer3_bn1.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.layer3_conv2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[ 2.0691e-01,  4.5253e-02,  2.4056e-02],\n",
       "                        [ 9.0154e-02,  2.8203e-02,  2.1624e-01],\n",
       "                        [ 1.0367e-01,  9.2139e-02,  4.7667e-01]],\n",
       "              \n",
       "                       [[-3.8690e-01, -8.1178e-02,  1.0655e-02],\n",
       "                        [ 1.1478e-02,  1.3834e-01,  3.3652e-02],\n",
       "                        [ 1.3283e-01,  2.5316e-01,  9.0482e-02]],\n",
       "              \n",
       "                       [[-1.0529e-02, -1.5294e-01, -4.2118e-01],\n",
       "                        [-8.3019e-02, -5.6267e-02, -9.1939e-02],\n",
       "                        [-8.8465e-02, -1.2450e-01, -2.0282e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.6750e-01, -1.4206e-01, -6.8503e-01],\n",
       "                        [ 3.4055e-01,  2.4090e-01, -2.2440e-01],\n",
       "                        [ 2.9064e-01,  2.8822e-01, -1.3762e-01]],\n",
       "              \n",
       "                       [[ 6.5361e-02,  1.4728e-01,  1.1917e-01],\n",
       "                        [-9.6565e-02, -8.0291e-02, -3.3301e-01],\n",
       "                        [-4.3605e-01, -2.4083e-01, -2.4110e-01]],\n",
       "              \n",
       "                       [[-1.7596e-01,  1.4274e-01,  4.1695e-01],\n",
       "                        [-1.9349e-01,  5.1556e-02,  1.4111e-01],\n",
       "                        [-3.7441e-01, -3.9186e-01, -3.4794e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5895e-02, -9.9481e-02,  9.0325e-02],\n",
       "                        [-1.2623e-01, -2.3893e-01, -5.4679e-02],\n",
       "                        [ 5.5008e-01,  4.3361e-01,  8.2782e-01]],\n",
       "              \n",
       "                       [[-3.7740e-01, -1.6539e-01, -1.5640e-01],\n",
       "                        [-3.1471e-01, -3.9437e-02,  5.7476e-03],\n",
       "                        [-2.8375e-01, -6.5457e-02, -4.4456e-02]],\n",
       "              \n",
       "                       [[-1.5802e-01, -1.2213e-01, -9.4963e-02],\n",
       "                        [-1.0840e-01, -6.0499e-03,  1.1372e-01],\n",
       "                        [-3.5568e-02,  1.7553e-01,  4.7117e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9926e-01,  1.3293e-01, -2.3042e-01],\n",
       "                        [ 1.9955e-01,  1.6123e-01, -1.5750e-01],\n",
       "                        [ 2.0066e-01,  1.8385e-01, -1.4664e-01]],\n",
       "              \n",
       "                       [[-2.7848e-01, -1.9067e-01, -6.1614e-02],\n",
       "                        [-3.8708e-02,  5.6172e-03,  8.7112e-02],\n",
       "                        [ 5.7015e-01,  5.9398e-01,  7.1219e-01]],\n",
       "              \n",
       "                       [[ 3.3743e-01,  1.6096e-01,  2.5004e-01],\n",
       "                        [ 1.2808e-01, -2.9763e-02,  7.1193e-02],\n",
       "                        [ 1.7164e-01, -9.4558e-03,  6.9228e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2696e-01,  2.7506e-01,  3.7243e-01],\n",
       "                        [ 9.7197e-02, -7.8568e-02, -1.0592e-01],\n",
       "                        [-1.8743e-01, -3.3355e-01, -3.0095e-01]],\n",
       "              \n",
       "                       [[-5.6619e-01, -2.8454e-01, -3.1341e-02],\n",
       "                        [-4.8212e-01, -5.6041e-02,  2.2020e-01],\n",
       "                        [ 1.9215e-01,  4.1505e-01,  5.8208e-01]],\n",
       "              \n",
       "                       [[-3.7194e-02,  4.7457e-02, -5.0489e-01],\n",
       "                        [-8.6692e-03,  1.9517e-01, -1.4044e-01],\n",
       "                        [-1.9970e-01,  6.0958e-02, -3.1598e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.2024e-01,  9.6608e-02, -2.4840e-01],\n",
       "                        [ 4.6610e-01,  1.1666e-01, -3.6623e-01],\n",
       "                        [ 4.7374e-01, -5.4097e-03, -5.2254e-01]],\n",
       "              \n",
       "                       [[-3.1823e-01,  1.0551e-01,  6.2663e-01],\n",
       "                        [-2.7337e-01, -1.0384e-02,  3.9075e-01],\n",
       "                        [-4.3354e-01, -1.6772e-01,  3.4520e-01]],\n",
       "              \n",
       "                       [[-7.9514e-02,  1.4968e-01,  3.2969e-01],\n",
       "                        [-1.8942e-01, -1.1324e-01, -3.9213e-02],\n",
       "                        [-4.3568e-01, -4.3730e-01, -4.3090e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1555e-01,  8.3343e-02,  1.3942e-01],\n",
       "                        [-1.2660e-01, -5.0004e-02,  1.5056e-01],\n",
       "                        [-3.5555e-01,  5.0250e-02,  4.6911e-01]],\n",
       "              \n",
       "                       [[-4.4836e-01, -1.2980e-01, -3.3361e-02],\n",
       "                        [-2.8501e-01, -1.6342e-01, -1.2695e-01],\n",
       "                        [ 9.1585e-02, -3.5920e-02, -2.9504e-01]],\n",
       "              \n",
       "                       [[ 9.4775e-02, -5.1501e-02, -1.2825e-01],\n",
       "                        [ 1.8758e-01,  6.4204e-02,  1.4717e-02],\n",
       "                        [ 4.8006e-01,  2.8820e-01,  1.5936e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.4226e-01, -6.5225e-02, -1.1925e-01],\n",
       "                        [-1.7250e-02,  5.7357e-02, -2.9229e-02],\n",
       "                        [ 3.7124e-02,  9.2237e-02,  5.7322e-02]],\n",
       "              \n",
       "                       [[ 2.9631e-01,  1.5494e-01, -2.5448e-01],\n",
       "                        [ 2.0238e-01,  2.0110e-01, -5.9471e-02],\n",
       "                        [ 8.4475e-02,  2.4284e-01,  3.0964e-01]],\n",
       "              \n",
       "                       [[ 5.3400e-01, -8.4504e-03, -3.4246e-01],\n",
       "                        [ 8.0422e-01,  1.3155e-01, -2.6822e-01],\n",
       "                        [ 1.4623e+00,  1.6339e-01, -8.1590e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3747e-01, -2.5708e-01, -7.9057e-02],\n",
       "                        [ 2.8793e-02,  1.2177e-01, -2.3383e-02],\n",
       "                        [ 2.1248e-01,  1.7032e-01, -8.9368e-02]],\n",
       "              \n",
       "                       [[ 1.4688e-01,  8.5997e-02, -3.4356e-02],\n",
       "                        [ 2.9711e-01,  3.0187e-01,  3.1153e-01],\n",
       "                        [-4.3045e-02, -4.5546e-02,  3.3576e-02]],\n",
       "              \n",
       "                       [[-1.3591e-01, -1.3356e-01, -5.4003e-02],\n",
       "                        [ 4.0529e-02,  2.0463e-01,  3.2825e-01],\n",
       "                        [-3.6217e-01, -3.3428e-01, -3.1528e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0432e-02, -4.2352e-01, -6.5776e-01],\n",
       "                        [-1.7650e-02, -3.4713e-01, -4.3387e-01],\n",
       "                        [ 4.3333e-01,  2.3423e-01,  2.0498e-01]],\n",
       "              \n",
       "                       [[-1.2897e-01, -1.8164e-01, -4.7527e-01],\n",
       "                        [-3.4615e-01, -4.1822e-01, -7.6589e-01],\n",
       "                        [ 2.6588e-01,  8.8567e-02, -1.8148e-01]],\n",
       "              \n",
       "                       [[ 6.4212e-01,  5.6655e-01,  6.0363e-01],\n",
       "                        [ 3.8803e-01,  2.6333e-01,  2.5213e-01],\n",
       "                        [ 1.2126e-01,  8.3010e-02,  1.6790e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5576e-02, -4.9749e-02, -6.0818e-02],\n",
       "                        [-3.3006e-04,  2.8461e-02,  2.4974e-02],\n",
       "                        [ 1.1615e-01,  1.3301e-01,  1.3568e-01]],\n",
       "              \n",
       "                       [[ 3.8342e-02, -6.9129e-02,  2.8444e-03],\n",
       "                        [ 2.7236e-02, -7.1324e-02,  1.4578e-02],\n",
       "                        [-7.5232e-02, -1.8446e-01, -4.7810e-02]],\n",
       "              \n",
       "                       [[ 7.4562e-03,  6.1851e-02, -5.5268e-02],\n",
       "                        [-3.8628e-02,  4.3219e-02, -1.0047e-01],\n",
       "                        [-5.3792e-02,  5.3915e-02, -9.1433e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2847e-02, -6.0267e-02, -8.4532e-02],\n",
       "                        [ 3.1805e-03, -8.8333e-02, -1.2267e-01],\n",
       "                        [-4.9016e-02, -1.2788e-01, -2.0205e-01]],\n",
       "              \n",
       "                       [[-1.4488e-02, -5.3484e-02, -4.6014e-02],\n",
       "                        [ 1.4975e-01,  8.0627e-02,  7.4251e-02],\n",
       "                        [ 1.5003e-01,  7.7631e-02,  6.6807e-02]],\n",
       "              \n",
       "                       [[-1.1723e-01, -2.1756e-02, -1.3434e-01],\n",
       "                        [-1.2060e-01, -4.0124e-02, -1.3745e-01],\n",
       "                        [-8.9683e-02, -7.5559e-02, -1.3631e-01]]]], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer3_conv2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 5.8063e-04, -9.1900e-04, -6.3351e-03, -1.0700e-03, -4.3434e-03,\n",
       "                      -4.4445e-03,  3.6159e-03,  5.7405e-03,  1.0354e-03,  4.7177e-03,\n",
       "                      -1.6764e-03, -3.3900e-03,  5.7097e-03, -2.5229e-03, -5.3534e-03,\n",
       "                       1.4445e-03,  4.4567e-03,  5.2441e-03, -2.6571e-03, -4.2417e-04,\n",
       "                      -4.4975e-03, -2.2323e-03,  3.8623e-03,  4.3883e-03,  3.8805e-03,\n",
       "                       8.8020e-04, -5.3510e-03,  3.7602e-03, -2.5671e-04,  3.6753e-03,\n",
       "                       4.6019e-03, -4.3285e-05,  4.0896e-03, -4.8525e-03,  1.4022e-03,\n",
       "                      -3.6029e-04,  3.3584e-03,  1.4942e-03,  5.5342e-03, -3.6163e-03,\n",
       "                       6.2737e-03, -1.7829e-03,  1.7980e-04, -4.2942e-03,  2.1222e-03,\n",
       "                       2.7107e-03, -5.5607e-03, -1.6148e-03, -4.0161e-03,  5.4681e-03,\n",
       "                       2.7120e-03, -3.9707e-03, -2.5452e-03,  1.3955e-03, -1.2708e-03,\n",
       "                       1.7095e-04,  5.5987e-03, -4.5435e-03, -4.9174e-03, -6.0929e-04,\n",
       "                      -4.2027e-03, -5.7383e-03, -5.6792e-03, -5.7610e-03, -3.7957e-03,\n",
       "                      -2.3550e-03,  6.0222e-03, -3.8229e-03, -1.9519e-03,  3.4407e-03,\n",
       "                      -1.4870e-03, -5.0551e-03,  3.1502e-03, -4.1741e-03, -4.4820e-03,\n",
       "                       5.6301e-03,  2.7541e-04, -6.2934e-03,  5.3535e-03,  1.9365e-03,\n",
       "                      -4.6488e-03, -3.5804e-03,  3.7674e-03, -5.7037e-03, -2.1627e-03,\n",
       "                      -2.6797e-03,  1.2101e-03, -3.7947e-03, -2.3743e-03,  1.3261e-03,\n",
       "                      -5.5197e-03, -5.1722e-03, -5.9357e-03, -5.6951e-03, -6.4951e-03,\n",
       "                      -9.0261e-04, -5.4098e-03,  5.7493e-03,  2.1601e-03,  2.1666e-03,\n",
       "                       4.8118e-03,  5.0652e-03, -4.5887e-03,  4.1994e-03,  4.5073e-04,\n",
       "                      -1.2476e-03,  4.0458e-04, -3.2912e-03,  2.0500e-03,  1.8815e-03,\n",
       "                      -5.3666e-03, -2.4600e-03, -2.1050e-03, -1.6584e-03, -1.0521e-03,\n",
       "                      -2.3716e-04, -4.4306e-03, -2.4698e-04,  8.2284e-04, -3.9697e-03,\n",
       "                      -2.5695e-03,  1.1062e-03, -5.9623e-03, -1.8142e-03,  5.9127e-03,\n",
       "                       6.7840e-03, -4.3182e-03,  1.7444e-03], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer3_bn2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([2.9010e-01, 2.1477e-01, 3.1250e-01, 3.2811e-01, 3.7185e-01, 4.0407e-01,\n",
       "                      3.7260e-01, 3.3071e-01, 3.3739e-01, 2.2719e-01, 3.8833e-01, 4.0059e-01,\n",
       "                      2.2973e-01, 3.9603e-01, 2.8784e-01, 2.6841e-01, 3.6820e-01, 3.2547e-01,\n",
       "                      2.6670e-01, 3.6029e-01, 3.7977e-01, 3.2687e-01, 1.9290e-01, 3.5159e-02,\n",
       "                      3.8824e-01, 4.1301e-01, 4.2045e-01, 3.7149e-01, 2.6612e-01, 2.9544e-01,\n",
       "                      2.7353e-01, 3.6577e-01, 3.5570e-01, 4.9165e-01, 2.1637e-01, 3.6163e-01,\n",
       "                      4.1661e-01, 6.9156e-03, 3.0999e-01, 1.7286e-01, 3.8433e-01, 1.7807e-01,\n",
       "                      2.9771e-01, 4.6451e-01, 2.6781e-01, 3.4682e-01, 2.4218e-01, 3.3205e-01,\n",
       "                      1.2771e-01, 3.7760e-01, 3.7671e-01, 4.2598e-01, 3.4359e-01, 1.7649e-01,\n",
       "                      3.1324e-01, 2.3931e-01, 3.2426e-01, 3.0827e-01, 4.1588e-01, 3.9127e-01,\n",
       "                      2.7559e-02, 2.9160e-01, 2.9674e-01, 4.0132e-01, 2.6582e-01, 4.1393e-01,\n",
       "                      3.5341e-01, 3.2878e-01, 3.2463e-01, 2.4084e-01, 3.0777e-01, 2.5604e-01,\n",
       "                      3.5720e-01, 3.9270e-02, 1.3600e-03, 3.2253e-01, 2.7382e-01, 3.1402e-01,\n",
       "                      4.5566e-01, 1.9930e-01, 3.1759e-01, 3.9289e-01, 2.1396e-01, 3.1073e-01,\n",
       "                      3.8856e-01, 3.9257e-01, 3.0643e-01, 4.0277e-01, 4.6255e-01, 2.6590e-01,\n",
       "                      3.5720e-01, 5.3998e-04, 4.4647e-01, 2.0060e-01, 4.9001e-01, 4.0179e-01,\n",
       "                      2.1139e-01, 3.3846e-01, 3.2614e-01, 1.8955e-01, 2.8457e-01, 2.4601e-01,\n",
       "                      1.1169e-02, 3.7414e-01, 3.3777e-01, 4.3686e-01, 2.4157e-02, 2.4849e-01,\n",
       "                      2.9122e-01, 2.9939e-01, 3.8460e-01, 3.9623e-01, 1.9955e-01, 4.1620e-01,\n",
       "                      2.6775e-01, 2.3143e-01, 3.4948e-01, 3.4573e-01, 3.6505e-01, 3.8223e-01,\n",
       "                      3.0425e-01, 5.5568e-01, 3.5998e-01, 3.0884e-01, 3.7717e-01, 2.4720e-01,\n",
       "                      3.0637e-01, 2.3825e-02], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer3_bn2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.2493, -0.2328, -0.1858, -0.3586, -0.5104, -0.9226, -0.4769, -0.2144,\n",
       "                      -0.5340,  0.1293, -0.6036, -0.4701, -0.0349, -0.4480, -0.0089, -0.4188,\n",
       "                      -0.8046, -0.2910, -0.2864, -0.2667,  0.0775, -0.1763, -0.4561, -0.1396,\n",
       "                      -0.4418, -0.8436, -0.0235, -0.3526, -0.5817, -0.1921, -0.3989, -0.7476,\n",
       "                      -0.2245, -0.6070, -0.0354, -0.4063, -0.6030, -0.0233, -0.3262, -0.0519,\n",
       "                      -0.4285, -0.2496, -0.3155, -0.5497, -0.3837, -0.5154, -0.2165, -0.6196,\n",
       "                      -0.1489, -0.4467, -0.1775, -0.9074, -0.6230,  0.0167, -0.3288, -0.4146,\n",
       "                      -0.2705, -0.4253, -0.7069, -0.4882, -0.2111, -0.3325, -0.2461, -0.6634,\n",
       "                      -0.0283, -0.3765, -0.4659, -0.4366, -0.2875, -0.1012, -0.3158, -0.3395,\n",
       "                      -0.3805, -0.1722, -0.1184, -0.5291, -0.5014, -0.4087, -0.8578, -0.2699,\n",
       "                      -0.2983, -0.7846, -0.0249, -0.4439, -0.5780, -0.3853, -0.3116, -0.5289,\n",
       "                      -0.7379, -0.3747, -0.5432, -0.0083, -0.5040,  0.1661, -0.7833, -0.8140,\n",
       "                      -0.2853, -0.6316, -0.4530, -0.0841, -0.1085, -0.1707, -0.1568, -0.2655,\n",
       "                      -0.4328, -0.3955, -0.1415, -0.3669, -0.3101, -0.3202, -0.8986, -0.2309,\n",
       "                       0.1182, -0.3682, -0.2190, -0.1989, -0.3796, -0.4478, -0.5371, -0.4662,\n",
       "                      -0.3319, -0.8741, -0.4430, -0.6576, -0.2486, -0.3235, -0.4283, -0.2600],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer3_bn2.running_mean',\n",
       "              tensor([ 151.4660,   59.9611,   19.3594,  -13.8629,   28.7473,  -71.3202,\n",
       "                        60.7776,   83.7348, -106.3184,  -69.3653,   48.1251,  -79.6190,\n",
       "                       216.7555,   58.9888,   31.3369, -121.2695,   -8.5133,   88.3474,\n",
       "                       149.5914,   76.2001,   51.9561,   87.2506,  109.4719,  -55.0517,\n",
       "                        65.0542,   23.2263,   52.4081,   28.9142,    3.7468,  105.4079,\n",
       "                       122.6120,  -67.3540,   45.4006,  -15.8060,  -74.6235,  -49.2571,\n",
       "                       -44.4408,  -37.1997,   50.8777,   65.0104, -135.3776,  -64.7519,\n",
       "                        38.9543,   80.9945, -248.1635, -102.6974, -216.9917,   60.5472,\n",
       "                      -123.6980,  -16.2844,   98.7526,  -15.1536,   37.2361,   54.6340,\n",
       "                      -161.2514,  126.7626,    9.8953,   42.9153,  -18.3638,   78.9745,\n",
       "                        -2.6013, -270.1612,  -93.0539, -108.2123,   -7.3789,  142.7243,\n",
       "                       199.3249,  -59.3121,   69.9580,  101.9464,  158.8102,  -56.7577,\n",
       "                        26.5085, -116.5729,   14.7997,  -92.8660, -123.0313,   26.3903,\n",
       "                      -176.6791, -341.3016,   87.6684,  -40.3664,  230.2839,   33.1874,\n",
       "                       -54.6279,  -44.4821,   94.4684,   42.9072,   24.1550,  -31.3757,\n",
       "                      -144.1809,   63.1919,   16.8967,  143.5806, -139.5111, -145.6569,\n",
       "                      -287.1762,  -48.4096,  -68.2123,  123.2392,  -46.8607, -169.6785,\n",
       "                       -61.4267,   28.7458,  -86.1332, -131.7986,  -85.2082,  130.9931,\n",
       "                      -213.3927, -122.9818,  -95.1659,    6.6857,  -92.6756,  -87.2356,\n",
       "                        82.0701,   32.1306,  107.6102,  -73.3746,   78.6052, -123.3017,\n",
       "                       101.7361,  -59.3023,   24.6048,   34.7619,  -84.1672,  221.0455,\n",
       "                        37.8883,  -86.4788], device='cuda:0')),\n",
       "             ('module.layer3_bn2.running_var',\n",
       "              tensor([ 6265.3018,  7872.2212,  4485.0181, 14763.2783,  8194.5439,  4477.2056,\n",
       "                       4921.8877,  5677.4487,  5357.3853, 18859.9082,  4282.9453,  5207.6494,\n",
       "                      18371.4941,  8633.2480, 33051.7422,  7520.5889,  5035.0869,  8152.7729,\n",
       "                       8665.6963,  5406.4653,  4191.7178,  4412.8115,  7296.8047,  6358.5444,\n",
       "                       6449.4702,  4294.5776,  6998.1694, 18326.8887,  7279.8276,  4683.4077,\n",
       "                       7648.5308,  7237.7764, 13286.1816,  5920.3984,  5443.2417,  5186.9663,\n",
       "                       4049.3276,  3056.3533,  4296.4233, 11456.2598,  7961.9165, 23028.5195,\n",
       "                       5604.7495,  6237.2373,  7018.6675,  4504.9946, 11701.1074,  4649.7119,\n",
       "                      18683.7812,  4748.1938,  8791.1914,  2122.0010,  7079.8716,  4806.2852,\n",
       "                      13841.3818,  9892.1367,  7661.3320,  4563.8369,  3978.7715,  6898.1548,\n",
       "                       6200.3750, 10179.7168, 11158.1387,  5629.9805, 10498.2129,  4165.4238,\n",
       "                      40465.2070,  6320.2178,  8184.8755,  6013.7632,  8462.7959,  5529.2695,\n",
       "                       4177.7163,  3675.0039,  1924.5616,  6643.8569,  7787.1343,  5295.8237,\n",
       "                       3177.9497, 27752.4707,  4509.5352,  2438.4258, 12840.4551,  3559.7744,\n",
       "                       6702.4053,  7309.4609,  6403.7842,  5044.4155,  4633.8530,  5654.2437,\n",
       "                       5440.2300,   414.0637,  4103.5322,  6636.5386,  5545.9194,  4077.0813,\n",
       "                      35329.8906,  9020.9326,  5250.3164,  8654.5537,  4460.8413, 20041.0840,\n",
       "                       2745.0698,  3534.5723,  4854.8667,  8123.1382,  4375.7554, 13110.7842,\n",
       "                      13294.2158,  5609.7568,  3386.4724,  5138.5737,  6781.4570, 12291.1533,\n",
       "                       6358.6973,  5128.7192, 13814.0488,  8120.7573,  5347.8110,  9651.0537,\n",
       "                      14037.6318,  1776.2524,  3444.9709,  5910.5288, 22562.8359, 11858.2617,\n",
       "                       8047.6494,  1893.4821], device='cuda:0')),\n",
       "             ('module.layer3_bn2.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.layer4_conv1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[-1.1641e-01, -1.6651e-01, -1.4204e-01],\n",
       "                        [ 2.7889e-01,  4.6649e-02,  1.9562e-01],\n",
       "                        [-4.6911e-01, -3.5653e-01, -5.4964e-01]],\n",
       "              \n",
       "                       [[-2.6232e-01, -1.2212e-01, -6.3742e-02],\n",
       "                        [-2.0701e-01, -6.7905e-02, -2.4880e-02],\n",
       "                        [-8.0250e-02, -1.2771e-01, -6.2539e-02]],\n",
       "              \n",
       "                       [[-2.1455e-01, -1.4962e-01, -3.2406e-01],\n",
       "                        [ 2.9452e-02,  5.0655e-01,  4.5505e-01],\n",
       "                        [-7.6752e-02, -1.3798e-01, -6.5174e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2329e-01,  6.3573e-02, -3.8640e-03],\n",
       "                        [ 1.3989e-01,  1.1442e-01, -2.9514e-02],\n",
       "                        [ 4.7382e-01,  1.0058e-02, -2.6382e-01]],\n",
       "              \n",
       "                       [[ 1.5306e-01,  2.9830e-02, -1.9435e-01],\n",
       "                        [ 1.6210e-01, -1.1227e-01, -3.1946e-01],\n",
       "                        [-6.3361e-01,  2.6517e-01,  3.5650e-01]],\n",
       "              \n",
       "                       [[-2.8998e-04, -1.6302e-02,  2.5408e-02],\n",
       "                        [-3.1622e-02, -3.7020e-02, -4.2153e-02],\n",
       "                        [ 5.0943e-02,  4.2763e-02,  5.2626e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8009e-01, -4.3034e-01, -3.7989e-01],\n",
       "                        [ 3.0221e-01, -1.4974e-03, -1.6331e-01],\n",
       "                        [ 3.0579e-01, -9.6413e-03, -2.0608e-01]],\n",
       "              \n",
       "                       [[-1.1135e-02,  4.6424e-02,  7.5539e-02],\n",
       "                        [-1.8704e-01, -1.3032e-01, -1.8552e-01],\n",
       "                        [-4.7071e-01, -4.7739e-01, -6.0502e-01]],\n",
       "              \n",
       "                       [[-4.3547e-01, -5.0953e-01, -6.0042e-01],\n",
       "                        [ 3.0335e-01,  3.2915e-01,  6.1334e-01],\n",
       "                        [-1.9131e-01, -2.8922e-01, -1.4334e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5847e-01, -4.8001e-01, -3.8017e-01],\n",
       "                        [-3.4529e-02, -2.4564e-01, -2.9292e-01],\n",
       "                        [-1.1650e-01, -2.2908e-01, -2.7761e-01]],\n",
       "              \n",
       "                       [[ 9.7121e-01,  7.7317e-01,  4.7114e-01],\n",
       "                        [-5.8578e-01, -3.0117e-01, -3.2270e-01],\n",
       "                        [-2.8580e-01, -2.9959e-01, -4.7013e-01]],\n",
       "              \n",
       "                       [[ 5.7429e-02,  1.3844e-02,  1.1379e-02],\n",
       "                        [-9.8306e-02, -1.3503e-01, -1.5149e-01],\n",
       "                        [-4.9722e-02, -6.6565e-02, -5.6386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3358e-01, -9.1471e-02, -4.2199e-01],\n",
       "                        [-7.5065e-03, -6.8012e-02, -2.3995e-01],\n",
       "                        [ 2.8616e-01, -1.8923e-02, -4.4752e-01]],\n",
       "              \n",
       "                       [[-4.4171e-01, -1.8493e-01, -1.5492e-01],\n",
       "                        [-1.5327e-01, -3.4085e-03,  1.3639e-02],\n",
       "                        [-1.8118e-01, -1.5340e-01, -1.7208e-01]],\n",
       "              \n",
       "                       [[-3.7250e-01, -9.1929e-02, -5.4230e-01],\n",
       "                        [-1.9224e-01, -1.1694e-01, -3.3052e-01],\n",
       "                        [ 1.9673e-01,  1.1459e-01, -1.7452e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0218e-01,  4.9473e-02,  2.0240e-02],\n",
       "                        [ 6.9513e-02,  3.2739e-01,  1.8727e-01],\n",
       "                        [-7.1721e-02,  1.5671e-01,  2.0525e-01]],\n",
       "              \n",
       "                       [[ 3.1305e-01,  2.5038e-01,  2.0709e-01],\n",
       "                        [-1.4723e-02,  6.5698e-02,  8.2447e-02],\n",
       "                        [-1.8610e-01, -5.4459e-02,  1.3553e-01]],\n",
       "              \n",
       "                       [[-1.3217e-01, -5.3757e-02, -1.0528e-02],\n",
       "                        [-1.3653e-02, -1.4318e-02, -6.1269e-03],\n",
       "                        [-3.4489e-02, -4.3273e-02, -4.6086e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2950e-01,  6.8298e-02,  3.3597e-01],\n",
       "                        [-1.5284e-02, -6.1593e-02,  1.3097e-01],\n",
       "                        [ 1.4459e-01,  3.3219e-02,  2.7831e-01]],\n",
       "              \n",
       "                       [[ 5.1610e-01,  4.2055e-01,  5.6847e-01],\n",
       "                        [ 8.4236e-02,  7.5185e-03,  1.9673e-01],\n",
       "                        [ 3.3678e-01,  4.3066e-01,  8.6666e-01]],\n",
       "              \n",
       "                       [[ 3.8594e-01,  4.3521e-01,  5.3092e-01],\n",
       "                        [ 2.3167e-01,  1.5523e-01,  2.4532e-01],\n",
       "                        [ 6.6727e-02, -1.3401e-01,  1.9733e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1339e-01,  2.9887e-01,  3.9132e-01],\n",
       "                        [ 2.5025e-02,  1.1961e-01,  2.6897e-01],\n",
       "                        [ 1.3973e-01,  2.3062e-01,  3.5811e-01]],\n",
       "              \n",
       "                       [[ 3.5056e-01,  3.3411e-01,  2.5672e-01],\n",
       "                        [-4.1393e-01, -2.6687e-01, -3.8327e-02],\n",
       "                        [ 7.0209e-02,  1.0754e-03,  1.4626e-01]],\n",
       "              \n",
       "                       [[-4.0875e-02, -5.7985e-03,  1.0670e-02],\n",
       "                        [ 1.0801e-02,  2.1656e-02,  4.7273e-02],\n",
       "                        [-9.4595e-03,  2.2958e-02,  5.3620e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0077e-01, -1.4262e-01, -6.1711e-02],\n",
       "                        [-1.7318e-02, -8.7506e-02, -1.0374e-01],\n",
       "                        [-9.9584e-02, -3.9725e-01, -4.2212e-01]],\n",
       "              \n",
       "                       [[ 3.2270e-01,  2.9513e-01,  2.8461e-01],\n",
       "                        [-9.1070e-02, -7.3239e-02, -5.4224e-02],\n",
       "                        [-5.0280e-01, -4.3950e-01, -4.6623e-01]],\n",
       "              \n",
       "                       [[-5.5568e-02, -8.4252e-02, -3.9785e-01],\n",
       "                        [ 1.7635e-01,  7.1698e-03,  1.1848e-02],\n",
       "                        [ 1.7091e-01,  2.4260e-01,  5.5838e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2859e-01, -1.7135e-01, -2.7444e-01],\n",
       "                        [ 3.7031e-02,  4.9635e-02, -2.1343e-01],\n",
       "                        [-2.0894e-01, -4.2912e-01, -7.3335e-01]],\n",
       "              \n",
       "                       [[ 3.9579e-01,  4.2241e-01,  4.3462e-01],\n",
       "                        [ 3.4270e-01,  3.6878e-01,  3.0623e-01],\n",
       "                        [ 2.2495e-01,  2.0197e-01,  2.7537e-02]],\n",
       "              \n",
       "                       [[ 1.1647e-01,  1.3483e-01,  1.6761e-01],\n",
       "                        [ 3.6229e-02,  7.4740e-02,  1.0480e-01],\n",
       "                        [-1.8025e-01, -1.6614e-01, -1.7488e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2080e-01, -2.1541e-01,  7.6166e-02],\n",
       "                        [ 4.2481e-03,  8.1860e-02,  1.5651e-01],\n",
       "                        [ 9.9694e-02,  9.6373e-02,  2.9596e-01]],\n",
       "              \n",
       "                       [[-2.1210e-01, -3.7664e-01, -4.7601e-01],\n",
       "                        [ 1.6299e-01, -8.9698e-03, -7.1441e-02],\n",
       "                        [ 4.8755e-01,  3.7720e-01,  4.0837e-01]],\n",
       "              \n",
       "                       [[-3.4944e-01,  9.2111e-03,  9.9921e-02],\n",
       "                        [-2.4134e-01, -1.5502e-01,  1.7221e-01],\n",
       "                        [-5.3175e-01, -5.0827e-01, -2.1162e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.2904e-02,  7.2802e-02, -1.6832e-01],\n",
       "                        [ 2.0906e-01,  9.4401e-02, -1.9383e-01],\n",
       "                        [ 3.0740e-01,  1.9837e-01,  9.8861e-02]],\n",
       "              \n",
       "                       [[ 4.2137e-01,  4.6946e-01,  6.1608e-01],\n",
       "                        [-1.1597e-01, -2.6500e-01, -7.1050e-01],\n",
       "                        [ 3.9369e-01,  2.1884e-01,  1.6111e-01]],\n",
       "              \n",
       "                       [[-1.1750e-01, -1.5144e-01, -1.3528e-01],\n",
       "                        [-7.2958e-02, -9.6759e-02, -9.1997e-02],\n",
       "                        [ 2.6626e-01,  2.2298e-01,  2.2039e-01]]]], device='cuda:0',\n",
       "                     requires_grad=True)),\n",
       "             ('module.layer4_conv1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 5.3206e-03, -1.0625e-04, -1.2284e-03, -3.2531e-03, -1.1874e-03,\n",
       "                       5.7178e-03,  6.2545e-03, -3.9004e-03,  6.7587e-03,  5.8814e-03,\n",
       "                      -2.6679e-03, -7.0231e-03, -1.8188e-03,  4.9239e-03,  3.0812e-03,\n",
       "                       3.6354e-03,  2.4444e-03,  5.2826e-03, -3.5542e-03, -5.5768e-03,\n",
       "                       4.7028e-03,  5.9463e-03, -2.4867e-04,  4.1198e-03, -5.4291e-04,\n",
       "                      -2.7285e-03,  4.7584e-04,  5.9281e-03,  6.0148e-03, -9.3309e-04,\n",
       "                      -2.2600e-03, -1.6058e-03,  9.0950e-04,  4.7788e-03, -2.3099e-03,\n",
       "                      -2.8965e-03,  2.2585e-04,  1.0051e-02,  4.2781e-03,  4.3894e-03,\n",
       "                      -5.0187e-04, -8.3579e-04, -6.4354e-04,  6.9210e-03,  4.6960e-03,\n",
       "                      -5.5837e-04,  5.7836e-03, -2.8968e-03, -3.1337e-03,  2.3060e-03,\n",
       "                      -5.0383e-03,  7.8449e-03,  5.0538e-03, -5.9958e-03,  6.9058e-03,\n",
       "                       2.4322e-03, -2.9596e-03,  2.5997e-03,  7.8555e-03, -2.9669e-03,\n",
       "                      -8.2786e-04, -4.3272e-04,  3.6724e-03,  6.1516e-03, -1.5633e-04,\n",
       "                       7.9329e-03, -8.7338e-04,  3.0716e-03,  4.8387e-03, -1.6777e-03,\n",
       "                       5.9820e-04,  3.0271e-03,  6.1624e-03, -2.3346e-03, -2.7773e-03,\n",
       "                      -1.9827e-03, -2.9594e-03,  6.3512e-03,  2.3849e-03, -6.2131e-03,\n",
       "                      -5.8034e-03,  6.3244e-03,  1.4880e-03,  2.9519e-03, -2.1877e-03,\n",
       "                       1.9824e-03, -6.5537e-03, -3.3276e-03,  8.6519e-04, -5.8097e-04,\n",
       "                       2.7678e-03,  7.6052e-03, -3.5967e-03,  5.1665e-04, -4.5293e-03,\n",
       "                       9.6034e-03,  5.2418e-03, -8.7137e-05, -7.9222e-04,  3.5013e-03,\n",
       "                      -4.5065e-03,  4.3032e-03,  7.2376e-03, -2.3757e-03,  7.9173e-03,\n",
       "                      -7.1366e-04,  2.1543e-03, -1.7560e-03,  5.1222e-03, -4.3017e-03,\n",
       "                      -5.2359e-04,  2.8217e-03,  1.0661e-03, -6.6281e-03, -2.6932e-03,\n",
       "                       3.5213e-03, -5.0961e-04, -1.8662e-03,  2.0227e-03,  1.9188e-03,\n",
       "                       8.0466e-03,  5.9791e-04, -3.0129e-03, -2.6682e-03,  6.3756e-03,\n",
       "                      -2.3037e-03, -4.3149e-03,  1.2304e-02,  1.9489e-03, -3.1788e-04,\n",
       "                       1.0299e-03, -3.9670e-03, -5.9949e-03, -2.0041e-03,  7.3993e-03,\n",
       "                      -2.4168e-03,  1.5919e-03, -2.0230e-03,  3.1359e-03,  5.0394e-03,\n",
       "                       6.1690e-03,  2.9579e-03,  3.3954e-03,  5.7882e-03, -3.5778e-03,\n",
       "                      -4.9630e-03,  6.0840e-03, -3.1913e-03, -6.0960e-03,  1.7516e-03,\n",
       "                      -5.7412e-05, -5.7680e-04, -8.7851e-03,  3.6747e-03, -2.2735e-03,\n",
       "                       8.7602e-04,  6.7770e-03,  5.8345e-03,  3.4352e-03, -2.1434e-03,\n",
       "                       1.3818e-03, -3.7194e-05, -3.0297e-03,  2.0006e-03, -2.4951e-04,\n",
       "                      -2.2297e-03, -3.6149e-03, -1.4753e-03,  6.3854e-03,  1.0066e-02,\n",
       "                       5.8221e-03,  1.0381e-04,  1.3711e-03,  6.3870e-04,  2.7294e-03,\n",
       "                      -2.0336e-03,  5.1221e-03, -1.7282e-03,  4.4150e-03,  2.5773e-03,\n",
       "                       5.0806e-03,  5.9508e-03,  4.9505e-03, -3.3979e-03, -5.6806e-03,\n",
       "                      -4.2855e-03,  6.8705e-03,  4.9480e-03,  1.5730e-03,  1.8846e-03,\n",
       "                      -9.5198e-04,  6.8647e-03, -5.3976e-03,  3.8338e-03,  3.9824e-03,\n",
       "                       5.0119e-03,  2.2065e-03,  5.9421e-03, -5.6974e-05,  2.3281e-03,\n",
       "                      -3.1930e-03,  3.4483e-03,  5.4439e-03, -1.5120e-03,  3.2002e-03,\n",
       "                       2.0238e-03,  5.6609e-03, -3.8650e-03, -1.0105e-03, -6.2143e-03,\n",
       "                      -4.1233e-03, -3.1995e-03,  2.0778e-03,  6.0933e-04,  3.7836e-03,\n",
       "                       9.2601e-03,  6.8354e-03,  3.4780e-03,  7.9255e-03, -4.4633e-03,\n",
       "                      -3.3663e-03, -4.6351e-04, -3.7658e-03, -3.1947e-03,  2.9862e-04,\n",
       "                       4.4695e-03, -2.8430e-04, -2.1747e-05, -3.0255e-03, -1.2136e-02,\n",
       "                      -2.7743e-03,  5.6037e-03,  7.7166e-04, -2.9017e-03, -5.4375e-03,\n",
       "                       4.3494e-03,  9.8472e-04, -7.5147e-04, -2.1516e-03, -5.3230e-03,\n",
       "                       4.5335e-03, -1.8678e-03,  7.4999e-03, -5.0965e-03,  3.0380e-03,\n",
       "                       4.9815e-03,  6.3658e-03, -1.5424e-03,  1.8208e-03, -1.0089e-03,\n",
       "                       4.3400e-03, -3.1403e-03,  1.9109e-04, -1.1218e-03, -2.3327e-04,\n",
       "                       5.1125e-03], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer4_bn1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([2.6450, 1.9600, 2.8570, 2.7659, 1.3436, 3.1667, 3.0286, 1.4960, 2.3973,\n",
       "                      2.6280, 1.7255, 2.6577, 3.0523, 2.0283, 2.5233, 2.2218, 2.4229, 2.3602,\n",
       "                      2.0219, 2.9147, 3.0643, 2.3009, 2.5629, 1.1765, 2.7268, 2.1820, 2.0817,\n",
       "                      2.4683, 2.6583, 2.7894, 2.3782, 1.2849, 2.9425, 2.2220, 2.3396, 2.4844,\n",
       "                      2.2725, 3.4132, 2.1513, 2.1279, 1.7413, 3.1603, 2.0345, 2.8361, 1.4580,\n",
       "                      1.6341, 2.0472, 2.9924, 2.8456, 2.6292, 2.6637, 1.5027, 3.1252, 2.5220,\n",
       "                      3.5262, 3.3776, 2.0023, 2.3579, 2.7648, 2.8253, 2.1313, 2.2658, 2.3187,\n",
       "                      2.8876, 2.8742, 2.0306, 3.6438, 3.0056, 1.6932, 3.1484, 2.9295, 2.8639,\n",
       "                      1.4369, 2.1205, 3.2456, 1.8491, 2.8103, 2.8359, 3.6514, 2.3332, 1.7905,\n",
       "                      1.4855, 2.4106, 2.7765, 3.4717, 3.0590, 1.2685, 2.2943, 2.7452, 2.3219,\n",
       "                      1.9567, 3.4834, 1.6831, 2.0838, 1.6466, 2.8231, 2.9316, 2.1688, 3.7182,\n",
       "                      2.9332, 2.2949, 3.4582, 2.5640, 2.0033, 2.7521, 1.9351, 3.0309, 2.3862,\n",
       "                      1.6543, 2.5105, 3.4064, 2.3370, 2.6543, 2.1276, 2.1981, 2.6715, 3.4817,\n",
       "                      2.4881, 3.0553, 1.4313, 2.1820, 2.6392, 1.8786, 2.8443, 3.1699, 2.3304,\n",
       "                      1.2922, 2.5571, 3.9997, 3.2149, 1.2294, 2.5199, 3.5019, 2.9934, 3.0942,\n",
       "                      3.0342, 2.7603, 3.5784, 2.4092, 1.5550, 2.6810, 3.4835, 3.1181, 3.5253,\n",
       "                      2.3628, 1.8456, 2.6686, 2.0533, 2.6755, 1.4078, 2.6652, 2.4535, 3.7280,\n",
       "                      2.6098, 2.3433, 1.4244, 2.8375, 3.4225, 2.3455, 3.2689, 1.9180, 2.3679,\n",
       "                      2.0783, 3.3882, 2.4586, 2.2869, 2.0269, 2.2152, 1.8194, 3.9524, 1.4028,\n",
       "                      2.8405, 2.0643, 2.5084, 1.9617, 2.1304, 1.8636, 2.5237, 2.3868, 1.7867,\n",
       "                      2.5403, 1.9300, 3.1456, 1.9418, 2.5191, 3.4862, 3.3334, 1.7323, 3.9048,\n",
       "                      2.3225, 3.3174, 2.1960, 2.2499, 3.5566, 1.4883, 1.9698, 2.9748, 3.5596,\n",
       "                      2.9383, 3.0541, 2.3257, 1.8345, 3.0537, 2.8754, 2.7980, 3.6634, 3.2214,\n",
       "                      1.9852, 2.3457, 2.3095, 3.5471, 3.7039, 2.6753, 2.7591, 3.5377, 2.6906,\n",
       "                      2.6861, 2.6923, 3.1950, 2.7634, 1.6302, 2.2973, 1.4955, 3.8580, 1.6928,\n",
       "                      3.1633, 2.2351, 3.0554, 3.4813, 3.4725, 1.9144, 3.1001, 3.0919, 3.2875,\n",
       "                      1.6715, 2.0650, 3.6158, 2.1913, 2.4460, 2.5592, 2.3030, 1.6563, 3.2498,\n",
       "                      2.6043, 3.4536, 3.1385, 3.7246, 1.8902, 3.2285, 2.0447, 2.6827, 1.9133,\n",
       "                      3.5030, 1.8660, 2.3568, 1.2919], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer4_bn1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-2.0402, -1.2101, -0.8513, -0.6714, -1.1146, -0.4337, -0.6921, -1.3769,\n",
       "                      -0.9694, -0.9153, -0.9928, -0.5876, -0.5810, -1.0927, -0.0980, -0.8117,\n",
       "                      -1.1662, -0.5308, -1.2004, -1.0945, -0.1442, -2.0303, -0.9965, -0.8913,\n",
       "                      -1.4426, -1.1874, -1.4002, -0.1450, -0.5128, -1.9232, -0.7620, -0.6464,\n",
       "                      -0.4751, -1.2008, -0.8714, -0.7636, -0.6766, -0.0633, -1.1318, -0.3271,\n",
       "                      -0.9827, -0.0048, -0.5334, -0.0720, -0.7036, -0.3184, -0.8214, -0.5287,\n",
       "                       0.7053, -0.1418, -0.7081, -0.9799, -0.3294, -0.2145, -0.1499,  0.4519,\n",
       "                      -0.9209, -0.8460, -0.3816, -1.1205, -0.2492, -0.9031, -1.9997, -0.8029,\n",
       "                      -0.6593, -0.6022, -0.3820, -0.6133, -0.7347, -0.3061, -1.2998, -1.1527,\n",
       "                      -0.3937, -0.8355, -0.1738, -0.4912, -1.1228, -0.1783, -0.1873, -0.9199,\n",
       "                      -1.6754, -0.8413, -0.2191,  0.1814, -0.0209, -0.5169, -0.5768, -0.9448,\n",
       "                      -0.3225, -0.3476, -1.2078, -0.4633, -1.2252, -0.8734, -0.6031, -0.9440,\n",
       "                      -0.7152, -0.7336, -0.2070, -0.7448, -0.5818, -0.3918, -1.0982, -0.8869,\n",
       "                      -0.3886, -0.7975, -0.6560, -1.1198, -1.1073, -0.9332,  0.3725, -1.1558,\n",
       "                      -0.6140, -0.9852, -1.1266, -1.4685, -1.1759, -0.1150, -0.5230, -0.9957,\n",
       "                       0.6316, -1.2096, -0.8705, -1.1717, -0.5904, -0.4747, -0.9573,  0.6120,\n",
       "                      -0.4016, -0.3068, -0.5978, -1.1487, -0.3569, -0.8502, -0.3547, -0.5952,\n",
       "                      -0.4435, -0.1697, -1.0753, -0.4334, -0.8021,  0.0650, -0.1218, -0.1232,\n",
       "                      -1.1935, -0.2310, -0.4981, -1.2540, -0.5305, -1.3300, -0.8406, -0.1378,\n",
       "                      -0.6328, -1.0779, -0.6957, -0.9712, -1.0059,  0.0531, -1.1217,  0.2698,\n",
       "                       0.2141, -1.5326, -1.3444,  0.1188, -0.7675, -0.8413, -0.6794, -1.5922,\n",
       "                      -1.1992, -0.6597, -0.9180, -0.5922, -0.8660, -0.7701, -1.6029,  0.3877,\n",
       "                      -1.2281, -0.3800,  0.2366, -0.4686, -0.8340, -0.8463, -1.0820, -0.4539,\n",
       "                      -0.4428, -0.5712, -0.3704, -1.2592, -0.9227, -0.7660,  0.1259, -1.5040,\n",
       "                      -0.8215,  0.2281, -0.8854, -1.0262, -1.5810, -2.1943, -0.6160, -0.1727,\n",
       "                      -1.1178, -1.3403, -0.7322, -0.3305, -0.9077, -0.6470, -0.5004, -0.7321,\n",
       "                      -1.4937, -1.5368, -0.6749, -0.5883, -0.3693, -0.9448, -0.1964, -0.6902,\n",
       "                      -0.9507, -1.3665, -0.2259, -0.9641, -0.6699, -0.7851, -1.1220,  0.4017,\n",
       "                      -0.9138,  0.3505, -0.0099,  0.2436, -0.7546,  0.4790, -0.9287, -1.4449,\n",
       "                       0.1218,  0.7411, -1.4255, -0.8335, -0.3701, -0.8377, -1.0287, -0.5609,\n",
       "                      -1.4403, -1.3228, -1.0300,  0.2864, -0.0787, -0.8126,  0.6410, -0.5140,\n",
       "                      -0.9643, -0.8200, -0.4182, -1.4545, -0.3068, -0.4987, -0.5472, -0.8621],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer4_bn1.running_mean',\n",
       "              tensor([-0.2893, -1.2893, -0.1012, -0.8280, -0.8571, -0.8274, -0.0934, -2.2050,\n",
       "                      -1.1497, -1.0303, -0.2036, -1.1491, -0.9575, -1.2605, -1.3612, -0.2552,\n",
       "                      -2.1945, -0.4565, -0.4798, -1.1436, -1.9106, -0.2295, -1.5961, -1.1749,\n",
       "                      -1.9061, -0.0334, -0.7834,  0.8032, -1.1776, -0.2187, -1.5935, -2.2588,\n",
       "                      -1.0389, -0.7354, -1.5370, -0.7347, -0.8785,  0.6235, -0.7350, -1.4969,\n",
       "                      -0.4419, -0.7470, -2.6372, -0.7275, -2.8283,  0.7840,  0.0564, -0.7632,\n",
       "                       0.2508, -1.2723,  0.0765, -1.4479, -0.8446, -2.1588, -0.9217, -0.5497,\n",
       "                      -0.2447,  0.1617, -2.0315, -0.3214, -3.3778, -0.5570, -0.3994, -1.1117,\n",
       "                      -1.0333, -0.9959, -0.5416, -0.2699, -2.7089, -1.0657, -0.8082, -0.1842,\n",
       "                      -3.1970, -1.2900,  0.8536, -1.4615, -0.6786, -0.3462,  0.4701, -1.4541,\n",
       "                      -0.7693, -1.1283, -1.5799, -1.5806, -0.7912, -0.9575,  0.2834, -0.8684,\n",
       "                      -1.0580, -0.5561, -1.7368, -0.2283, -1.3244, -0.3319, -1.0412, -0.1824,\n",
       "                      -1.2354, -0.9019, -1.2157, -0.7590, -1.2652, -1.5119, -0.5574, -0.2590,\n",
       "                       0.0059, -1.4371, -0.6477, -0.4550, -0.4508, -1.7929,  0.0930, -1.7699,\n",
       "                      -0.6783, -0.4302, -0.3637, -1.1216, -0.0419, -1.0315, -0.3486, -0.2630,\n",
       "                      -3.1569, -0.7156, -2.5709, -2.8048, -0.9160, -0.3639, -0.4091, -3.2937,\n",
       "                      -0.9821,  0.3148, -2.4005, -1.5180,  0.3028, -0.8948, -0.9956, -0.7713,\n",
       "                      -0.2247, -0.8209, -1.1359, -1.0207, -0.3426, -0.3728, -0.5296,  0.0862,\n",
       "                      -0.3973, -1.0358, -0.0996, -0.6494, -1.1487, -0.0920, -0.4191, -1.9346,\n",
       "                      -0.1001, -1.5323, -0.9989, -0.6480, -1.4260, -1.1554, -0.3670, -0.6268,\n",
       "                      -3.6589, -1.4247, -1.1099, -0.5952, -0.3733, -0.8759,  0.0527, -0.6697,\n",
       "                       0.1432, -1.2419, -1.6332, -1.0999, -1.5692, -0.4072, -0.0463, -2.8575,\n",
       "                      -0.8170,  0.7306, -3.2649, -0.5231, -0.9040, -1.3278, -0.9650, -1.8346,\n",
       "                      -1.7128, -1.4685, -2.0678, -0.4651, -0.0749, -0.8406, -0.9449, -1.7186,\n",
       "                      -0.3593, -0.4194, -1.5198, -0.5666, -1.1200, -0.2498, -0.6462, -1.1322,\n",
       "                      -1.6828, -2.3442, -1.2460, -1.1225, -1.0573, -0.2319, -0.4089, -1.6585,\n",
       "                      -1.0254, -0.0340, -0.3790, -0.2945, -1.7208, -0.5290,  0.0621, -0.7358,\n",
       "                      -1.3097, -0.6554, -0.2594, -0.3664, -0.2037, -1.4986, -2.8544, -0.5644,\n",
       "                      -1.3917, -0.6602,  0.2830,  0.0073, -1.0571,  1.0273, -1.6438, -0.9043,\n",
       "                       0.0718,  1.4074, -1.3394, -1.8522, -0.8203, -1.0894, -1.1850, -0.5803,\n",
       "                      -2.1886, -1.4690, -0.9591, -2.6042, -1.1421, -1.4529,  0.2380, -0.6442,\n",
       "                      -1.4052, -0.2312,  0.3853, -1.2362,  0.2981,  1.4338,  0.8137, -1.2156],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layer4_bn1.running_var',\n",
       "              tensor([ 1.4441,  3.8946,  4.9021,  5.8548,  3.0617,  4.9166,  3.8710,  3.6183,\n",
       "                       6.1510,  3.4512,  4.4447,  3.6484,  3.8092,  4.0042,  3.4768,  4.4482,\n",
       "                       3.6361,  2.9135,  3.7215,  4.8669,  4.4351,  1.3276,  5.6999,  3.6899,\n",
       "                       2.9011,  2.1134,  2.8796,  5.9474,  4.9291,  1.4020,  6.3941,  4.2534,\n",
       "                       3.8574,  5.0961,  4.4337,  3.1738,  4.0626,  5.4025,  4.8098,  3.4541,\n",
       "                       4.2729,  4.3407,  4.0086,  4.4083,  4.9155,  4.9256,  3.7556,  4.2993,\n",
       "                       8.0866,  5.6746,  3.4606,  2.1826,  4.9390,  5.1447,  4.7893,  4.0840,\n",
       "                       4.1150,  5.5069,  5.4049,  3.1871,  4.5575,  2.5091,  1.4853,  4.0046,\n",
       "                       2.5348,  3.3785,  3.8124,  4.1189,  3.8313,  4.5457,  3.7420,  3.5950,\n",
       "                       5.0682,  4.5023,  7.0088,  4.1279,  3.8622,  4.3305,  5.5085,  3.6752,\n",
       "                       3.3580,  3.2906,  5.2925,  4.8803,  3.7374,  3.8671,  3.2884,  2.2129,\n",
       "                       5.5344,  5.8464,  3.0259,  4.5165,  2.4497,  2.3069,  4.7766,  2.4791,\n",
       "                       4.1572,  3.3842,  4.8887,  4.2403,  3.7667,  3.9039,  3.3094,  3.5145,\n",
       "                       6.3236,  3.4251,  4.9224,  3.5423,  3.7703,  3.8719,  3.7613,  3.3694,\n",
       "                       5.0650,  6.5148,  2.8829,  4.0245,  2.5202,  3.5252,  4.2877,  4.2452,\n",
       "                       6.6915,  4.6017,  5.1114,  5.7875,  3.4182,  3.4847,  3.6879,  6.9014,\n",
       "                       4.8892,  4.8529,  5.1778,  5.3412,  3.5545,  3.6040,  3.7574,  5.1052,\n",
       "                       4.7902,  2.3091,  2.8000,  4.6650,  3.2408,  3.1907,  5.4805,  4.3088,\n",
       "                       3.0692,  5.3879,  5.6388,  3.3254,  3.1102,  3.9982,  3.5205,  4.9540,\n",
       "                       3.3797,  2.9900,  4.9671,  3.6588,  3.2451,  3.7618,  2.6251,  4.2767,\n",
       "                       8.0185,  2.4082,  3.1504,  3.7412,  4.6155,  4.8332,  5.4088,  3.6210,\n",
       "                       2.6440,  3.2982,  4.0898,  3.8099,  4.4814,  3.3351,  2.0301,  6.5680,\n",
       "                       3.7738,  4.2092,  6.6717,  3.7146,  3.4907,  4.2081,  4.6861,  4.8865,\n",
       "                       5.9068,  4.3155,  3.4869,  3.3063,  3.8968,  3.1060,  6.8049,  2.8600,\n",
       "                       1.9672,  3.4005,  4.2418,  4.9785,  2.9630,  0.8796,  4.2856,  4.6561,\n",
       "                       2.7303,  3.2828,  4.2152,  3.4148,  4.4072,  2.4759,  4.4385,  4.2371,\n",
       "                       2.8935,  4.8387,  4.3801,  3.8534,  3.8339,  3.0978,  5.2947,  3.1990,\n",
       "                       4.5327,  3.5371,  2.4697,  2.7084,  4.9766,  4.3130,  3.8243,  3.7268,\n",
       "                       4.0885,  4.4686,  6.4551,  9.6292,  3.8924,  4.8856,  9.2151,  2.2880,\n",
       "                       3.5983, 11.6286,  2.9054,  5.3054,  5.6857,  4.6255,  3.2478,  2.9314,\n",
       "                       3.0901,  3.1859,  3.4042,  5.6684,  4.9084,  2.7363,  4.3275,  4.7005,\n",
       "                       6.0665,  2.8548,  4.2266,  2.3115,  4.9804,  5.0519,  5.1514,  3.7971],\n",
       "                     device='cuda:0')),\n",
       "             ('module.layer4_bn1.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.layer4_conv2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[[[ 0.2762,  0.2997,  0.2923],\n",
       "                        [ 0.0930,  0.1794,  0.0905],\n",
       "                        [-0.0777,  0.0321, -0.0321]],\n",
       "              \n",
       "                       [[-0.5565, -0.1676, -0.0061],\n",
       "                        [-0.4193, -0.0937,  0.0329],\n",
       "                        [ 0.0194,  0.1541,  0.2092]],\n",
       "              \n",
       "                       [[ 0.2543,  0.0329,  0.0245],\n",
       "                        [ 0.2764,  0.0037, -0.0236],\n",
       "                        [ 0.4098,  0.2748,  0.1619]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.9046, -0.2830,  0.1318],\n",
       "                        [-0.5402, -0.0293,  0.3261],\n",
       "                        [-0.2041,  0.1507,  0.4830]],\n",
       "              \n",
       "                       [[-0.7263, -0.2231,  0.3139],\n",
       "                        [-0.3765, -0.0839,  0.2779],\n",
       "                        [-0.2102,  0.0722,  0.3074]],\n",
       "              \n",
       "                       [[-0.1034, -0.1956, -0.1685],\n",
       "                        [ 0.1041, -0.0955, -0.0828],\n",
       "                        [ 0.2202,  0.0342,  0.0555]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4733,  0.3645,  0.0091],\n",
       "                        [ 0.3903,  0.2973, -0.0101],\n",
       "                        [ 0.4554,  0.5727,  0.3026]],\n",
       "              \n",
       "                       [[ 0.3605,  0.0613, -0.5764],\n",
       "                        [ 0.3035, -0.0457, -0.6375],\n",
       "                        [ 0.2885, -0.0341, -0.6536]],\n",
       "              \n",
       "                       [[-0.1374, -0.3720, -0.0476],\n",
       "                        [ 0.1546, -0.2365, -0.1076],\n",
       "                        [ 0.5345,  0.0173, -0.0664]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0098,  0.0741,  0.2401],\n",
       "                        [-0.1365, -0.0895, -0.0577],\n",
       "                        [-0.0263, -0.0439, -0.0618]],\n",
       "              \n",
       "                       [[ 0.1368, -0.0012,  0.1555],\n",
       "                        [ 0.0661, -0.0728,  0.0128],\n",
       "                        [ 0.2849,  0.0512,  0.0259]],\n",
       "              \n",
       "                       [[ 0.1161, -0.0393,  0.0034],\n",
       "                        [ 0.3071,  0.0283, -0.0048],\n",
       "                        [ 0.6070,  0.3315,  0.3245]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2872, -0.1052,  0.1953],\n",
       "                        [-0.1721, -0.1956,  0.0116],\n",
       "                        [-0.1991, -0.1388, -0.0994]],\n",
       "              \n",
       "                       [[ 0.0025,  0.0750,  0.5363],\n",
       "                        [-0.1656, -0.1811,  0.3035],\n",
       "                        [-0.4185, -0.3219,  0.2955]],\n",
       "              \n",
       "                       [[ 0.1444,  0.0902,  0.0253],\n",
       "                        [ 0.0428, -0.0848, -0.1340],\n",
       "                        [-0.0789, -0.0682,  0.0300]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1062,  0.0109, -0.0522],\n",
       "                        [-0.2707, -0.0938, -0.2891],\n",
       "                        [-0.4541, -0.4052, -0.7792]],\n",
       "              \n",
       "                       [[-0.4056, -0.1671,  0.2338],\n",
       "                        [-0.2949, -0.0840,  0.2477],\n",
       "                        [-0.3643,  0.0380,  0.3034]],\n",
       "              \n",
       "                       [[-0.1092,  0.0777,  0.1457],\n",
       "                        [-0.0576,  0.0540, -0.0213],\n",
       "                        [-0.2153, -0.1686, -0.2147]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1274, -0.0117, -0.0170],\n",
       "                        [ 0.2583,  0.0864, -0.0386],\n",
       "                        [ 0.3197,  0.1663,  0.1179]],\n",
       "              \n",
       "                       [[ 0.1014, -0.1078, -0.4269],\n",
       "                        [-0.2180, -0.0401, -0.1936],\n",
       "                        [-0.0631, -0.0156, -0.2662]],\n",
       "              \n",
       "                       [[-0.7712, -0.3695,  0.0516],\n",
       "                        [ 0.0960,  0.1671,  0.2991],\n",
       "                        [ 0.8595,  0.4377,  0.2235]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1113,  0.0272, -0.3703],\n",
       "                        [-0.1277, -0.1801, -0.5725],\n",
       "                        [-0.3406, -0.4184, -0.7675]],\n",
       "              \n",
       "                       [[-0.1993, -0.3623, -0.7053],\n",
       "                        [ 0.2998, -0.0592, -0.5370],\n",
       "                        [ 0.5348,  0.0220, -0.6019]],\n",
       "              \n",
       "                       [[ 0.3973,  0.2213,  0.1580],\n",
       "                        [ 0.2359, -0.0640, -0.1818],\n",
       "                        [ 0.1232, -0.2366, -0.2839]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2440,  0.1210, -0.1030],\n",
       "                        [-0.1769,  0.2690, -0.0274],\n",
       "                        [ 0.0806,  0.5371,  0.2178]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0099, -0.1895],\n",
       "                        [ 0.3600, -0.0354, -0.2635],\n",
       "                        [ 0.1386, -0.0472, -0.0645]],\n",
       "              \n",
       "                       [[-0.5339, -0.5292, -0.9668],\n",
       "                        [-0.0986,  0.0585, -0.2494],\n",
       "                        [-0.3103, -0.0521, -0.3424]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.3906, -0.6695, -0.0667],\n",
       "                        [-0.3900, -0.5740, -0.0253],\n",
       "                        [-0.0499, -0.2495,  0.2219]],\n",
       "              \n",
       "                       [[ 0.2147, -0.0838, -0.1490],\n",
       "                        [ 0.2514, -0.0610, -0.2513],\n",
       "                        [ 0.1580, -0.0570, -0.4602]],\n",
       "              \n",
       "                       [[-0.0161, -0.0205,  0.0703],\n",
       "                        [-0.1803, -0.2492, -0.2641],\n",
       "                        [ 0.3732,  0.3321,  0.2586]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1304,  0.0962, -0.3739],\n",
       "                        [ 0.0377,  0.1596, -0.1848],\n",
       "                        [ 0.9868,  1.1259,  0.5369]],\n",
       "              \n",
       "                       [[-0.2607, -0.1158,  0.1603],\n",
       "                        [-0.1558,  0.0349,  0.3165],\n",
       "                        [ 0.2960,  0.3454,  0.5980]],\n",
       "              \n",
       "                       [[-0.2764,  0.0206, -0.3561],\n",
       "                        [-0.0591,  0.0802, -0.1513],\n",
       "                        [ 0.0354, -0.2089, -0.4682]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1987,  0.1042,  0.3510],\n",
       "                        [-0.3009, -0.0711,  0.1261],\n",
       "                        [-0.3768, -0.2245, -0.1726]],\n",
       "              \n",
       "                       [[-0.1193, -0.0787, -0.3104],\n",
       "                        [-0.0689, -0.1602, -0.5095],\n",
       "                        [ 0.1722, -0.0211, -0.3609]],\n",
       "              \n",
       "                       [[-0.3954, -0.1663,  0.0446],\n",
       "                        [-0.0927,  0.0205, -0.0039],\n",
       "                        [ 0.0153,  0.0861, -0.0305]]]], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer4_conv2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-2.1826e-03,  3.6792e-03,  2.5294e-03, -1.0033e-03,  1.4254e-03,\n",
       "                       2.4280e-03, -1.1675e-03,  4.4705e-03,  1.9256e-03, -4.6044e-03,\n",
       "                      -7.7429e-04, -2.9747e-03,  4.2701e-04, -1.2167e-03,  6.8664e-04,\n",
       "                      -1.0890e-03, -4.7788e-04,  3.7323e-03,  2.1979e-03,  2.9377e-03,\n",
       "                       2.8972e-03,  4.1699e-04, -2.2896e-04, -1.7379e-03,  1.9482e-04,\n",
       "                       1.4330e-03, -3.9842e-03,  1.4339e-03,  3.7604e-03, -4.2428e-03,\n",
       "                       3.2250e-03, -3.6740e-03,  1.4121e-03,  2.9932e-03,  3.4900e-03,\n",
       "                      -9.0554e-04,  2.2001e-03,  1.6027e-03,  2.7612e-03, -2.5759e-03,\n",
       "                       1.3432e-03, -1.6137e-03, -4.0998e-03,  3.7136e-03,  3.9362e-04,\n",
       "                      -4.1984e-03,  3.3320e-03, -2.1639e-03,  2.5899e-03, -1.8426e-03,\n",
       "                      -4.3966e-03,  1.5394e-03,  1.7196e-03,  9.2895e-04, -1.0772e-03,\n",
       "                      -2.1259e-03, -1.8616e-03,  1.6502e-03, -2.6822e-03,  2.4344e-03,\n",
       "                       2.6543e-03,  1.4774e-03,  3.0756e-03, -8.2516e-04, -1.5077e-03,\n",
       "                      -1.1025e-03, -3.8806e-03,  3.2616e-03, -2.3029e-03,  1.4368e-03,\n",
       "                       3.1804e-03,  1.7024e-03,  8.1169e-04, -1.7960e-03,  1.7041e-03,\n",
       "                      -4.2793e-04,  3.1860e-03,  3.6942e-04,  2.8597e-03,  2.7280e-03,\n",
       "                      -1.4283e-03,  2.6731e-03,  2.4310e-03, -4.2784e-03, -2.2085e-03,\n",
       "                       2.2549e-03, -8.1715e-04, -8.8864e-04,  3.4807e-03, -1.1973e-04,\n",
       "                       4.4692e-03, -1.7203e-03, -6.8178e-04, -2.0050e-03, -3.6359e-04,\n",
       "                       2.0637e-03,  1.5336e-03,  2.0543e-03, -9.5776e-04,  4.3460e-03,\n",
       "                       3.5026e-03, -3.4628e-03,  2.5470e-03, -2.7023e-03, -3.4726e-03,\n",
       "                       2.1047e-03,  2.0663e-03,  4.5901e-03,  3.6530e-03,  8.3768e-04,\n",
       "                       4.6484e-03,  5.6017e-04,  2.9654e-03, -1.4195e-03, -1.8752e-03,\n",
       "                      -4.2167e-03,  9.6672e-04,  1.2093e-03, -1.4693e-03,  3.4250e-03,\n",
       "                       3.7726e-03,  2.8289e-03, -1.8238e-03,  5.6093e-04,  3.6350e-03,\n",
       "                       2.9580e-03, -2.1227e-03,  5.7483e-04, -4.5054e-03,  2.9919e-03,\n",
       "                       1.5801e-03,  3.6145e-03,  3.9815e-03,  2.3563e-04,  3.3308e-03,\n",
       "                      -3.4761e-03,  1.1160e-03,  3.8610e-03,  7.5096e-04,  2.5731e-03,\n",
       "                       4.6237e-03,  1.6084e-03, -1.2748e-03, -6.8155e-04,  1.1888e-03,\n",
       "                      -8.4591e-04,  2.6127e-03,  6.4102e-04, -5.0246e-03,  3.6766e-03,\n",
       "                       3.1091e-03,  9.6007e-04,  3.7681e-04, -3.7248e-03,  3.2052e-03,\n",
       "                       3.3622e-04, -3.2085e-03,  1.5445e-03,  4.1995e-03,  1.9299e-03,\n",
       "                      -1.2524e-03,  9.9588e-04, -2.6620e-03,  2.8786e-03, -1.8416e-03,\n",
       "                       4.2807e-03,  7.2497e-04, -7.2662e-04, -2.9734e-03,  2.8613e-04,\n",
       "                       3.6621e-04, -7.1575e-04, -3.4635e-03,  9.8450e-04, -4.1018e-04,\n",
       "                       2.0532e-03,  4.3811e-03, -1.3902e-04,  2.6930e-03,  1.3619e-05,\n",
       "                       5.0782e-04,  6.2465e-04, -2.8243e-03, -4.0871e-03, -5.0170e-03,\n",
       "                       4.2153e-03, -1.5328e-03, -4.6220e-03,  1.4445e-03, -3.7976e-03,\n",
       "                       2.6120e-03, -3.8732e-03,  3.3338e-03, -2.8719e-03,  1.2298e-03,\n",
       "                       3.2182e-03,  1.3540e-03, -1.1088e-04,  3.7323e-04, -2.2177e-03,\n",
       "                       4.1993e-04, -1.5917e-03,  7.8038e-04, -3.4484e-03,  3.4939e-03,\n",
       "                       3.1012e-03,  2.0356e-04, -8.9828e-04,  2.4003e-03, -3.6663e-03,\n",
       "                      -2.6829e-03, -1.4548e-03,  3.3027e-03, -2.7235e-03, -9.0962e-04,\n",
       "                      -3.3095e-03,  1.7540e-03, -2.1900e-03, -4.3415e-03, -1.0130e-03,\n",
       "                      -4.0076e-03,  1.4071e-03, -4.0595e-03, -4.2052e-03,  3.2822e-03,\n",
       "                       3.2210e-03, -4.3054e-03,  6.6824e-04,  1.5160e-03, -3.3350e-04,\n",
       "                      -3.4771e-03,  2.6975e-03, -1.1283e-03, -1.9678e-03, -3.1604e-03,\n",
       "                      -2.2450e-03, -4.5069e-03, -1.4389e-03,  3.8917e-03, -2.3353e-03,\n",
       "                       1.2656e-03,  1.0629e-03,  2.3399e-03,  1.9936e-03, -1.8658e-04,\n",
       "                       8.0963e-04,  1.8174e-03,  2.5103e-03,  4.0167e-03, -2.4525e-03,\n",
       "                       3.9445e-03, -1.8412e-03,  1.0784e-04,  2.4479e-03,  1.5144e-03,\n",
       "                      -4.7096e-03], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer4_bn2.weight',\n",
       "              Parameter containing:\n",
       "              tensor([0.9433, 0.6747, 1.3159, 0.9491, 0.9193, 0.8887, 0.7582, 0.8984, 1.1702,\n",
       "                      0.8786, 0.9757, 0.6250, 0.9388, 0.8911, 0.8214, 1.0886, 0.9346, 0.3872,\n",
       "                      0.6308, 1.0665, 0.6595, 0.9255, 0.9810, 0.8557, 0.6945, 0.6536, 0.3584,\n",
       "                      1.0348, 0.8200, 0.6989, 0.8934, 0.4918, 1.3292, 0.6299, 0.8658, 0.9771,\n",
       "                      0.8982, 0.8976, 0.7717, 0.6962, 0.6500, 0.6691, 0.7696, 1.4752, 0.8100,\n",
       "                      0.8752, 0.7702, 0.6672, 1.1685, 1.1010, 0.8862, 0.9292, 0.6216, 0.5689,\n",
       "                      0.7504, 0.8637, 0.8988, 0.8233, 1.0383, 0.8539, 1.0455, 0.6210, 1.1258,\n",
       "                      0.5402, 0.6461, 1.2008, 1.0299, 0.6097, 0.6929, 1.0405, 1.2326, 0.8776,\n",
       "                      1.0147, 0.8139, 1.2363, 0.8129, 0.9727, 0.5508, 0.9003, 0.9045, 0.9646,\n",
       "                      0.6761, 1.0746, 1.0422, 0.3786, 0.7864, 0.8782, 0.7858, 0.6622, 0.7902,\n",
       "                      0.6409, 1.2795, 0.8418, 0.9676, 0.3870, 0.9319, 0.5974, 1.1507, 0.8586,\n",
       "                      0.9022, 0.8570, 1.3330, 0.7662, 1.0539, 0.6051, 0.5457, 0.6890, 0.7148,\n",
       "                      0.6166, 0.7992, 0.7795, 0.8715, 0.9181, 0.9511, 1.0488, 0.9371, 0.4552,\n",
       "                      1.0391, 1.0645, 1.0516, 0.8638, 0.8966, 1.0770, 1.0564, 0.7590, 0.5787,\n",
       "                      1.1598, 0.7922, 0.8084, 0.7759, 0.8673, 1.2237, 1.0989, 0.9843, 1.2941,\n",
       "                      1.2080, 0.8015, 0.7518, 0.7794, 0.8375, 0.8918, 0.8755, 0.9181, 0.7125,\n",
       "                      0.6287, 0.8177, 0.5990, 1.3102, 0.8830, 0.9028, 1.1747, 0.9542, 0.8885,\n",
       "                      0.5134, 0.6500, 1.0084, 0.9385, 0.9654, 0.6377, 0.5955, 0.7470, 0.7321,\n",
       "                      0.8404, 0.6182, 0.4759, 1.0373, 1.0495, 0.3585, 0.8809, 0.9017, 0.9204,\n",
       "                      0.9824, 0.7981, 0.7192, 0.7162, 1.0601, 0.7647, 1.0712, 0.5231, 1.2063,\n",
       "                      0.6695, 0.8865, 0.7554, 0.6583, 0.8681, 1.3591, 0.9553, 1.0080, 1.0430,\n",
       "                      0.7839, 1.0040, 1.0183, 0.7870, 0.9421, 0.9935, 1.0174, 0.9264, 0.7207,\n",
       "                      1.0924, 1.0230, 0.5542, 1.1006, 0.5616, 0.8360, 0.5367, 0.7858, 0.8697,\n",
       "                      1.1154, 1.0373, 1.2050, 1.4473, 0.9419, 0.9291, 0.9263, 0.9592, 0.9786,\n",
       "                      0.9530, 1.2139, 0.9418, 0.7649, 0.9617, 0.8209, 0.9240, 0.9129, 1.1355,\n",
       "                      0.8518, 0.7671, 0.9760, 0.7649, 0.7606, 0.7314, 0.6033, 1.0397, 0.6819,\n",
       "                      1.2073, 0.9615, 1.0266, 0.6013, 0.7461, 0.9229, 1.0076, 0.9104, 0.8516,\n",
       "                      0.7949, 1.2852, 1.2798, 1.0716, 0.8776, 0.8910, 0.7746, 1.0576, 0.7497,\n",
       "                      1.1012, 0.8971, 0.7930, 0.9366], device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer4_bn2.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.8938, -0.6599, -1.4387, -0.8379, -0.9052, -0.7396, -0.6830, -0.7814,\n",
       "                      -1.2993, -0.7637, -0.9495, -0.5959, -0.7269, -0.8034, -0.7793, -1.0865,\n",
       "                      -0.7728, -0.3836, -0.5539, -1.0225, -0.4856, -0.8262, -0.8716, -0.7462,\n",
       "                      -0.4978, -0.5542, -0.2334, -0.9420, -0.7550, -0.7235, -0.8191, -0.3660,\n",
       "                      -1.4961, -0.2832, -0.7804, -0.8417, -0.6853, -0.8334, -0.6091, -0.6298,\n",
       "                      -0.4630, -0.5312, -0.6391, -1.4135, -0.7676, -0.7163, -0.6465, -0.5400,\n",
       "                      -1.2021, -1.0511, -0.6903, -0.7713, -0.4665, -0.4308, -0.5661, -0.8418,\n",
       "                      -0.7405, -0.6984, -1.1359, -0.6437, -1.0168, -0.3888, -1.0839, -0.4710,\n",
       "                      -0.5551, -1.1586, -0.9236, -0.3725, -0.5191, -1.0106, -1.1378, -0.7593,\n",
       "                      -0.8795, -0.4324, -1.2632, -0.6419, -0.9304, -0.4311, -0.8105, -0.8563,\n",
       "                      -0.8379, -0.5261, -1.0972, -1.0524, -0.1911, -0.6879, -0.7129, -0.7195,\n",
       "                      -0.6132, -0.6146, -0.3450, -1.2219, -0.6987, -0.8759, -0.4250, -0.7732,\n",
       "                      -0.5429, -1.0972, -0.7494, -0.8794, -0.7976, -1.4891, -0.6855, -0.8805,\n",
       "                      -0.4604, -0.4625, -0.5715, -0.5552, -0.3630, -0.7376, -0.6681, -0.7561,\n",
       "                      -0.8797, -1.0483, -0.8926, -0.7628, -0.3092, -0.9663, -0.9199, -0.9542,\n",
       "                      -0.8706, -0.8597, -0.9838, -1.0487, -0.6773, -0.4055, -1.0620, -0.5565,\n",
       "                      -0.6874, -0.7299, -0.7168, -1.2411, -1.1155, -0.8955, -1.3411, -1.0764,\n",
       "                      -0.8330, -0.6842, -0.7076, -0.8521, -0.7790, -0.7609, -0.6742, -0.6160,\n",
       "                      -0.5918, -0.6936, -0.3706, -1.1254, -0.8266, -0.8724, -1.2158, -0.9756,\n",
       "                      -0.7606, -0.3737, -0.3997, -0.9163, -0.8333, -0.9799, -0.4693, -0.4687,\n",
       "                      -0.6025, -0.5243, -0.7697, -0.5151, -0.3433, -1.0082, -0.8975, -0.2563,\n",
       "                      -0.7263, -0.6522, -0.7633, -1.1920, -0.7664, -0.6540, -0.6076, -1.0238,\n",
       "                      -0.5954, -1.0147, -0.1929, -1.2674, -0.2669, -0.7548, -0.6129, -0.3901,\n",
       "                      -0.7045, -1.2740, -0.8664, -0.9940, -1.2083, -0.5808, -0.9364, -0.9642,\n",
       "                      -0.7805, -0.7090, -0.9263, -0.9256, -0.9103, -0.6440, -1.0887, -0.7598,\n",
       "                      -0.5021, -0.9295, -0.2204, -0.6498, -0.4976, -0.5766, -0.8531, -1.1465,\n",
       "                      -0.9525, -1.1719, -1.4368, -0.8443, -0.8873, -0.8322, -0.7953, -0.7522,\n",
       "                      -0.7867, -1.0791, -0.9800, -0.6260, -0.7542, -0.6996, -0.8620, -0.7760,\n",
       "                      -0.9556, -0.7383, -0.5539, -0.8861, -0.6883, -0.6549, -0.6937, -0.5131,\n",
       "                      -0.9947, -0.5629, -1.1694, -0.8640, -0.7879, -0.4662, -0.5720, -0.7482,\n",
       "                      -0.8026, -0.9580, -0.7545, -0.7881, -1.3675, -1.4135, -0.9693, -0.7733,\n",
       "                      -0.7492, -0.5285, -1.0182, -0.7802, -0.9957, -0.8739, -0.6387, -0.6972],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.layer4_bn2.running_mean',\n",
       "              tensor([ -66.5591,  -70.6715,  -71.9362,  -63.5670,  -73.4668,  -48.1082,\n",
       "                       -59.7645,  -33.0240,  -99.0878,  -22.1635,  -46.0760,  -60.1400,\n",
       "                       -42.3055,  -39.1230,  -51.1361,  -64.7758,  -48.9012,   10.9756,\n",
       "                       -64.4049,  -58.4715,  -26.7952,  -68.5703,  -29.6194,  -39.4890,\n",
       "                       -27.6466,  -25.5272,  -26.6791,  -30.4891,  -38.8047,  -80.6299,\n",
       "                       -50.8431,   -1.8701,  -67.3968,   76.5347,  -51.9009,  -55.0042,\n",
       "                       -21.6173,  -71.5201,  -52.2181,  -50.8841,  -20.8041,  -41.7522,\n",
       "                       -45.2386,  -40.0504,  -71.1641,  -56.6417,  -44.7522,  -45.7034,\n",
       "                       -57.2337,  -34.9530,  -50.5988,  -50.4282,  -47.8359,  -35.3664,\n",
       "                       -17.2083,  -53.5464,  -33.6764,  -45.6456,  -66.0948,  -29.3829,\n",
       "                       -54.6974,    6.1117,  -56.3412,  -34.1890,  -61.7523,  -37.9847,\n",
       "                       -38.1274,   -8.7431,   -3.1596,  -46.0539,  -32.4952,  -24.3513,\n",
       "                       -52.0738,    9.4803,  -95.2868,  -30.5521,  -65.1525,  -32.7776,\n",
       "                       -62.2970,  -45.9095,  -39.5567,  -26.7518,  -75.2486,  -58.0661,\n",
       "                       -35.5527,  -70.9428,  -53.2796,  -46.6856,  -43.2239,  -30.7035,\n",
       "                       -44.0649,  -47.3411,  -59.2876,  -42.9726,  -18.9224,  -51.7690,\n",
       "                       -40.5480,  -48.8036,  -57.8408,  -46.0041,  -57.7316,  -85.5132,\n",
       "                       -48.2413,  -37.7407,  -38.3895,   15.3630,  -51.9908,  -45.4335,\n",
       "                        22.6452,  -49.3474,   -3.9906,  -24.2264,  -70.1746,  -85.3518,\n",
       "                       -34.3981,  -66.9622,   -3.2080,  -78.6244,  -33.5429,  -72.0104,\n",
       "                       -65.0553,  -71.6233,  -49.4600,  -64.4137,  -26.8057,  -42.4162,\n",
       "                       -61.1568,  -25.7024,  -78.3178,  -40.6205,  -28.2429,  -49.0018,\n",
       "                       -61.6747,  -56.6122,  -50.1271,  -49.0070,  -70.9862,  -69.4986,\n",
       "                       -30.8313,  -30.8399,  -54.0578,  -40.1034,  -37.3916,  -42.0119,\n",
       "                        61.6795,  -50.9802,   41.5613,  -34.9555,  -63.5616,  -52.0658,\n",
       "                       -51.3514,  -58.3023,  -64.1162,  -20.5242,  -59.6179,  -16.5478,\n",
       "                       -36.1608,  -47.8622,  -47.4625,  -52.0912,  -48.9720,  -91.1613,\n",
       "                       -62.0262,  -53.8020,    4.4527,  -59.6485,  -28.1139,   -9.3812,\n",
       "                        -9.7167,  -41.7574,  -32.5222, -114.9258,  -79.3195,  -21.8787,\n",
       "                       -57.3122,  -45.1841,  -52.2756,  -46.5229,   90.9298,  -92.5318,\n",
       "                        72.2719,  -43.7660,  -25.7645,   -6.2553,    3.5123,  -81.7361,\n",
       "                       -73.0951,  -52.9187,  -78.7372,  -70.3154,  -42.6603,  -41.9705,\n",
       "                       -71.7950,  -19.4981,  -36.8984,  -75.8877,  -66.7297,  -62.3449,\n",
       "                       -38.6541,  -34.8755,  -47.3475,  -25.8355,   37.4940,  -21.3135,\n",
       "                       -49.4236,  -52.9357,  -64.1381,  -68.4217,  -46.3738,  -26.4043,\n",
       "                       -44.1838,  -58.6062,  -47.5633,  -48.4947,  -64.7826,  -68.2363,\n",
       "                       -66.4051,  -49.0014,  -28.9750,  -52.0056,  -57.0047,   -2.7923,\n",
       "                       -55.9772,  -79.8377,  -44.8365,  -67.8892,  -38.2132,  -49.3237,\n",
       "                       -54.2476,  -26.8792,  -84.5751,  -45.9891,  -62.6094,  -27.0084,\n",
       "                       -63.8623,  -26.0443,  -34.2627,  -40.6162,  -21.6265,  -42.3569,\n",
       "                       -36.8015,  -37.9231,  -32.1711,  -73.0041,  -58.7639,  -72.7661,\n",
       "                       -46.3943,  -54.7956,  -47.0587,   -0.1499,  -42.0466,  -15.8064,\n",
       "                       -66.1212,  -59.5696,  -58.4108,  -25.1879], device='cuda:0')),\n",
       "             ('module.layer4_bn2.running_var',\n",
       "              tensor([12024.3945, 17582.1348,  9431.1025, 14120.5254, 12705.4199, 12217.8428,\n",
       "                      12478.3584, 10940.9697, 13412.0947, 10292.2725, 11242.9639, 14448.6982,\n",
       "                      12824.1426,  9713.1289, 10675.6455,  8878.0732,  9884.7705, 17671.8574,\n",
       "                      10739.7344,  8720.3027, 19806.4492, 15810.4346, 11954.2959, 11104.4131,\n",
       "                      14106.3418, 11861.0957, 24635.2734, 13713.8066, 11474.2705, 11198.7471,\n",
       "                      10420.6582, 18548.3535, 11719.4502, 31668.2109, 16114.8047, 12444.8555,\n",
       "                      15502.9463, 10668.7578, 15417.2393, 14430.0498, 13797.8350, 10977.1201,\n",
       "                       9237.8945, 10099.8945, 11290.5156, 16482.0312, 15389.5498, 13409.3730,\n",
       "                       9284.2412, 10032.9121,  9253.2393, 11604.1299, 13756.1768, 14250.8145,\n",
       "                      14855.1494, 10132.2246, 15859.0342,  9326.1348, 13165.2754, 11704.6182,\n",
       "                      15227.3174, 20414.9160, 10966.0508, 17953.2305, 15704.6064, 10825.1338,\n",
       "                       9854.8057, 17166.5098, 20917.5664,  9750.7080,  8669.8242, 13437.9365,\n",
       "                      10282.1660, 12839.7734, 19000.1484, 12137.5576, 12588.9912, 11726.3848,\n",
       "                      14962.5400, 14290.6094, 11801.8125, 14027.6426, 10440.4834, 10246.7422,\n",
       "                      24861.9824,  9907.8770, 12147.1055, 14246.3496,  8773.9990, 11907.4023,\n",
       "                      19638.7734, 12659.0742, 13765.1973, 10506.3496, 10972.5059, 14222.1797,\n",
       "                       9579.5410, 11213.7236, 12276.7041,  9949.4746, 11245.9785, 12489.2998,\n",
       "                      11923.2139, 13658.0645, 12844.4717, 14389.0625,  9589.6133, 11337.7188,\n",
       "                      21353.0449,  9690.3203, 12329.1553, 11614.5068, 10522.4980,  9775.2686,\n",
       "                      10657.3135,  9610.6436, 19415.0059, 11740.5635, 12347.8184, 11446.2461,\n",
       "                      24506.9277, 12287.3262, 11006.7168,  9672.6211, 11255.7158, 18579.0625,\n",
       "                      11749.5684, 13024.4141, 16404.7031,  9876.7461,  9094.5410, 10342.7461,\n",
       "                      12062.0811, 11144.5293,  8665.4746,  8711.1885, 12213.6982, 13534.4941,\n",
       "                      13255.1152, 10213.4307, 11413.9639, 15804.1309, 10172.7607, 13502.6865,\n",
       "                      13714.7539,  9254.8467, 17667.0898,  8097.5273,  9862.6025, 13683.3135,\n",
       "                      10915.1396, 15807.4668, 19094.2148, 25253.6172, 11687.1396, 10693.2715,\n",
       "                       8658.9590, 12038.4121, 14142.1064, 12429.4561, 13896.0947, 13464.8896,\n",
       "                      11215.6709, 11964.1953, 11807.6357, 13471.8574, 13814.4209, 18681.5176,\n",
       "                      16278.4121, 14313.8115, 16222.0322,  9772.7803, 13833.4375, 11952.4189,\n",
       "                      11881.1826,  9480.5898, 14506.5039,  8338.3184, 29390.0566, 14812.3740,\n",
       "                      22161.0293, 10273.3164, 13084.7061, 16103.0264,  8946.6631, 11416.1758,\n",
       "                      12584.6514, 11755.1943,  9722.7100, 12598.4746, 10373.2930, 12166.0518,\n",
       "                       9504.1260,  7173.0054, 10280.5234, 10923.7148, 11982.9531, 11240.6289,\n",
       "                       9283.0322,  9290.6826, 15529.7686, 11247.2783, 25381.6211, 11189.3955,\n",
       "                      12271.1270, 13266.2129, 12100.0225, 14718.8438, 13658.5674,  8013.7329,\n",
       "                      11427.3848, 11198.1299, 13423.1943, 11040.7109, 12024.8428, 14596.1855,\n",
       "                      18244.2480,  9962.3008, 10668.8115, 12464.3545, 10663.4805, 10639.8311,\n",
       "                      12061.7383, 12843.0684, 10680.5400, 12880.3096, 13968.9424,  9187.7373,\n",
       "                      12717.3770, 10036.6201, 11315.1992,  9678.3701, 11975.1396, 11703.0186,\n",
       "                      13567.7402, 13170.2979, 10752.1182, 13319.4648, 15186.1953, 12914.8652,\n",
       "                      10838.7070, 11910.3799, 17426.4043, 10303.8740,  9730.9111, 12794.7617,\n",
       "                      10815.3936, 11057.8887, 10491.5928, 18891.4961, 10896.7842, 12145.6816,\n",
       "                      12601.6943, 10058.9844, 12365.0137, 11311.4658], device='cuda:0')),\n",
       "             ('module.layer4_bn2.num_batches_tracked',\n",
       "              tensor(65001, device='cuda:0')),\n",
       "             ('module.fc1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.8216,  0.4744,  1.6537,  ...,  0.9990, -0.1667,  0.8515],\n",
       "                      [ 0.0408, -0.0602, -0.3697,  ...,  0.2512,  0.0249, -0.1000],\n",
       "                      [-1.2182,  0.3671,  0.2464,  ...,  0.8870, -1.5814,  0.1298],\n",
       "                      ...,\n",
       "                      [-1.2097, -1.4408, -1.2532,  ..., -0.2273,  0.0199,  0.3245],\n",
       "                      [ 0.5831, -0.2473,  0.7559,  ..., -1.4188,  0.0804,  0.0981],\n",
       "                      [-0.7047, -0.0797,  0.5781,  ...,  0.5239,  0.4817, -0.8206]],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.fc1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.0257,  0.0040,  0.0252, -0.0058,  0.0090, -0.0291, -0.0314,  0.0007,\n",
       "                       0.0139, -0.0136], device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers1.1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[ 0.0363,  0.0021, -0.0261,  ..., -0.0077, -0.0007, -0.0128],\n",
       "                      [ 0.0290,  0.0278,  0.0043,  ...,  0.2562,  0.2588,  0.2357],\n",
       "                      [ 0.0015,  0.0788, -0.0347,  ...,  0.0939,  0.0878,  0.0876],\n",
       "                      ...,\n",
       "                      [-0.0066,  0.0889, -0.0393,  ...,  0.0849,  0.0697,  0.0753],\n",
       "                      [-0.0534,  0.1007,  0.1647,  ..., -0.0758, -0.0894, -0.0743],\n",
       "                      [-0.0136, -0.0838,  0.0308,  ..., -0.1927, -0.1706, -0.1748]],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers1.1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.2054,  0.1200,  0.0990, -0.1382,  0.3643,  0.3813,  0.3218, -0.0860,\n",
       "                      -0.2192, -0.1404, -0.3742, -0.4842, -0.4002,  0.1914, -0.3999, -0.2004,\n",
       "                       0.7516, -0.2067,  0.3993, -0.4779,  0.4162,  0.2757,  0.3563,  0.3345,\n",
       "                       0.1346,  0.0427, -0.3712, -0.1612, -0.1987,  0.0767, -0.0585, -0.7256],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers2.1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.0623,  0.0437,  0.1495,  ..., -0.0944, -0.0813, -0.0933],\n",
       "                      [-0.0051, -0.0491, -0.1012,  ...,  0.0032, -0.0171, -0.0041],\n",
       "                      [ 0.0411,  0.0223, -0.0340,  ...,  0.0405,  0.0558,  0.0428],\n",
       "                      ...,\n",
       "                      [ 0.0672, -0.0434, -0.0461,  ...,  0.1136,  0.0960,  0.0948],\n",
       "                      [-0.0142, -0.3580, -0.0771,  ..., -0.0877, -0.0846, -0.0881],\n",
       "                      [-0.1025, -0.1002, -0.0323,  ...,  0.1683,  0.1722,  0.1778]],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers2.1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([-0.1897, -0.0708, -0.0253, -0.0756, -0.0549, -0.0924, -0.0985, -0.0082,\n",
       "                      -0.5436, -0.0860,  0.1735, -0.1238, -0.1300, -0.0072,  0.1671, -0.1409,\n",
       "                       0.0660, -0.0795, -0.1363,  0.0258,  0.0826, -0.1984, -0.0138, -0.0172,\n",
       "                       0.0425, -0.1442, -0.0694,  0.0392, -0.1500, -0.0058,  0.4745, -0.1821,\n",
       "                       0.0813, -0.0935, -0.0743,  0.0009, -0.1847, -0.1096, -0.0792, -0.0653,\n",
       "                      -0.0613, -0.0880, -0.0262, -0.1979, -0.1476, -0.0521, -0.1238, -0.0588,\n",
       "                      -0.0267,  0.0567, -0.0365, -0.3818, -0.1243, -0.0239, -0.0666, -0.0342,\n",
       "                      -0.1897, -0.1859, -0.0410, -0.0945, -0.0620, -0.1145, -0.1740, -0.2163],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers3.1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.0029, -0.0381,  0.0419,  ...,  0.1101,  0.1065,  0.1068],\n",
       "                      [ 0.0502, -0.0068, -0.0149,  ...,  0.0119, -0.0068, -0.0093],\n",
       "                      [-0.0829,  0.1641,  0.0011,  ...,  0.0268,  0.0204,  0.0239],\n",
       "                      ...,\n",
       "                      [ 0.1246, -0.0693, -0.0883,  ...,  0.0277,  0.0108,  0.0227],\n",
       "                      [ 0.0367,  0.0968,  0.0210,  ...,  0.0153,  0.0117,  0.0384],\n",
       "                      [ 0.0138,  0.0919, -0.0084,  ...,  0.0495,  0.0545,  0.0600]],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers3.1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.1271, -0.1808,  0.0510, -0.0959,  0.0378, -0.3594, -0.1826, -0.0467,\n",
       "                       0.0153,  0.2103, -0.1068, -0.0741, -0.1018, -0.0510, -0.1189, -0.0129,\n",
       "                      -0.1031, -0.1766, -0.0586,  0.0084, -0.1959,  0.0075,  0.0383, -0.0827,\n",
       "                      -0.2042, -0.1942, -0.1030, -0.1379, -0.1667, -0.1352, -0.0672, -0.2067,\n",
       "                      -0.1363, -0.0875, -0.0063, -0.2311,  0.0610, -0.0169,  0.0287, -0.0306,\n",
       "                      -0.0127,  0.0091, -0.0651, -0.1269, -0.0429, -0.0393, -0.1632, -0.0667,\n",
       "                      -0.0685,  0.1750, -0.0104, -0.0951, -0.0118, -0.0461, -0.2116, -0.0285,\n",
       "                      -0.0562, -0.0375, -0.1346, -0.2403,  0.1200, -0.0756, -0.1602, -0.2492,\n",
       "                      -0.1029, -0.3512, -0.0958, -0.0276, -0.0924, -0.0664, -0.0629, -0.1543,\n",
       "                       0.0833, -0.0693, -0.1458,  0.1095, -0.2144, -0.0292, -0.0734, -0.3165,\n",
       "                      -0.2379,  0.1136, -0.0948, -0.0495, -0.0824, -0.0275,  0.2088, -0.0143,\n",
       "                      -0.1019, -0.0215,  0.3163, -0.0128, -0.0916,  0.0391,  0.0197, -0.0164,\n",
       "                      -0.0964, -0.0150, -0.0394, -0.0388,  0.0799, -0.0087, -0.1092, -0.0853,\n",
       "                      -0.1062, -0.0720, -0.0424, -0.0755,  0.0634, -0.1750, -0.0219,  0.0181,\n",
       "                      -0.0669, -0.1120, -0.1189,  0.0059,  0.1359, -0.0110, -0.0312,  0.1025,\n",
       "                       0.0405, -0.0790, -0.0508, -0.1117, -0.0544,  0.0187,  0.0285,  0.1118],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers4.1.weight',\n",
       "              Parameter containing:\n",
       "              tensor([[-0.0705,  0.0652,  0.0043,  ...,  0.0374,  0.0245,  0.0342],\n",
       "                      [ 0.0033, -0.0561,  0.0074,  ...,  0.0288,  0.0217,  0.0105],\n",
       "                      [-0.1907,  0.1392,  0.0175,  ...,  0.0651,  0.0587,  0.0518],\n",
       "                      ...,\n",
       "                      [-0.0435, -0.0604,  0.0903,  ..., -0.0010,  0.0077, -0.0014],\n",
       "                      [-0.0435, -0.0018,  0.1238,  ...,  0.0404,  0.0406,  0.0418],\n",
       "                      [ 0.0405,  0.1689, -0.1472,  ...,  0.0125,  0.0281,  0.0114]],\n",
       "                     device='cuda:0', requires_grad=True)),\n",
       "             ('module.emb_layers4.1.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ 0.0046,  0.0080, -0.0777, -0.0988, -0.0219, -0.0233,  0.0078, -0.0003,\n",
       "                      -0.0555, -0.0876, -0.0141,  0.0004, -0.0536, -0.0080, -0.0651,  0.0310,\n",
       "                      -0.0602, -0.0582, -0.0173, -0.0649, -0.0343,  0.0054, -0.0361, -0.0062,\n",
       "                      -0.0234, -0.0420, -0.0111, -0.0156,  0.0374, -0.0542, -0.0796,  0.0021,\n",
       "                      -0.0859, -0.0155, -0.0300, -0.0351, -0.0694, -0.0516,  0.0178, -0.0542,\n",
       "                      -0.0660, -0.0233, -0.0286, -0.0471,  0.0073, -0.0107, -0.0018, -0.0473,\n",
       "                       0.0175, -0.0413, -0.0156, -0.0232, -0.0423, -0.0457, -0.0648, -0.0358,\n",
       "                      -0.0112, -0.0350, -0.0319, -0.0362,  0.0115, -0.0740, -0.0534,  0.0459,\n",
       "                      -0.0350, -0.0449, -0.0592, -0.0601, -0.0213, -0.0874, -0.0077, -0.0172,\n",
       "                      -0.0077,  0.0040, -0.0410, -0.0336, -0.0231, -0.0153, -0.1494, -0.0780,\n",
       "                      -0.0270,  0.0060, -0.0073, -0.0576,  0.0247, -0.0726,  0.0043, -0.0989,\n",
       "                      -0.0736, -0.0093, -0.0720,  0.0291, -0.0782,  0.0121,  0.0073, -0.0473,\n",
       "                       0.0099, -0.0093, -0.0559, -0.0430, -0.0235, -0.0656, -0.0220,  0.0084,\n",
       "                      -0.0014, -0.0251,  0.0182, -0.0583,  0.0021, -0.0533, -0.0597, -0.0646,\n",
       "                      -0.0356, -0.0828, -0.0216, -0.0617,  0.0136, -0.0182, -0.0789, -0.0178,\n",
       "                      -0.1053, -0.0708, -0.0165, -0.0369,  0.0136, -0.0435, -0.0161, -0.1263,\n",
       "                      -0.0491, -0.1119, -0.0066,  0.0389, -0.0502, -0.0202, -0.0282, -0.0594,\n",
       "                      -0.0506, -0.0436, -0.0157, -0.0613, -0.0250, -0.0485, -0.0147, -0.0014,\n",
       "                      -0.0058, -0.0201, -0.0431, -0.0455, -0.0738, -0.0077, -0.0435, -0.0547,\n",
       "                      -0.0741, -0.0548, -0.0264, -0.0253, -0.1291, -0.0590, -0.0341, -0.0707,\n",
       "                      -0.0895, -0.0315, -0.0228, -0.0073, -0.0428, -0.0295,  0.0224, -0.0505,\n",
       "                      -0.0511, -0.0804, -0.0320, -0.0570, -0.0177,  0.0068, -0.0319, -0.0581,\n",
       "                      -0.0261, -0.0549, -0.0244, -0.0152, -0.0591, -0.0096, -0.0187, -0.0122,\n",
       "                      -0.0528, -0.0327, -0.1068, -0.0379, -0.0525, -0.0418, -0.0341, -0.0213,\n",
       "                      -0.0105, -0.0530, -0.0061, -0.0403, -0.0177, -0.0226,  0.0073, -0.0303,\n",
       "                      -0.0153, -0.0466, -0.0399, -0.0206, -0.0613, -0.0971, -0.0439, -0.0549,\n",
       "                       0.0327, -0.0845, -0.0386, -0.0606, -0.0033, -0.0431, -0.0297, -0.0112,\n",
       "                      -0.0321, -0.0564, -0.0476, -0.0243,  0.0154, -0.0306, -0.0022, -0.0928,\n",
       "                      -0.0096, -0.0836, -0.0220,  0.0078, -0.0246,  0.0163,  0.0222, -0.0726,\n",
       "                       0.0020,  0.0257, -0.0693, -0.0270, -0.0329, -0.0249, -0.0381, -0.0345,\n",
       "                      -0.0490,  0.0090, -0.0577, -0.0997, -0.0311, -0.0211, -0.0764, -0.0393,\n",
       "                      -0.0036, -0.0382, -0.0184, -0.0979,  0.0306, -0.0020,  0.0137,  0.0052],\n",
       "                     device='cuda:0', requires_grad=True))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = th.load(args.classifier_path)\n",
    "model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecd9b5a0-1878-4292-99ac-757091382f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_2D(\n",
       "  (layer1_conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1_conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1_bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer2_conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer2_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer2_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer2_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer2_bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer3_conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer3_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer3_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer4_conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer4_bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer4_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer4_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer4_bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (emb_layers1): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  )\n",
       "  (emb_layers2): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (emb_layers3): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (emb_layers4): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.log(\"loading classifier...\")\n",
    "classifier = create_CNN(**args_to_dict(args, CNN_defaults().keys()))\n",
    "\n",
    "loaded_state_dict = th.load(args.classifier_path)\n",
    "new_state_dict = OrderedDict()\n",
    "for n, v in loaded_state_dict.items():\n",
    "    name = n.replace(\"module.\",\"\") # .module    (\".module\",\"\") \n",
    "    new_state_dict[name] = v\n",
    "\n",
    "classifier.load_state_dict(new_state_dict)\n",
    "\n",
    "classifier.to(dist_util.dev())\n",
    "if args.classifier_use_fp16:\n",
    "    classifier.convert_to_fp16()\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7395eeb9-1d6c-4e10-a772-a6768e3d337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fc8e8c91ff0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m classes\n\u001b[1;32m     24\u001b[0m sample_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     25\u001b[0m     diffusion\u001b[38;5;241m.\u001b[39mp_sample_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_ddim \u001b[38;5;28;01melse\u001b[39;00m diffusion\u001b[38;5;241m.\u001b[39mddim_sample_loop\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdev\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m sample \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     38\u001b[0m gathered_samples \u001b[38;5;241m=\u001b[39m [th\u001b[38;5;241m.\u001b[39mzeros_like(sample) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dist\u001b[38;5;241m.\u001b[39mget_world_size())]\n",
      "File \u001b[0;32m/data/yjpak/guided-diffusion/guided_diffusion/gaussian_diffusion.py:473\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample_loop\u001b[0;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mGenerate samples from the model.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03m:return: a non-differentiable batch of samples.\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_sample_loop_progressive(\n\u001b[1;32m    474\u001b[0m     model,\n\u001b[1;32m    475\u001b[0m     shape,\n\u001b[1;32m    476\u001b[0m     noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    477\u001b[0m     clip_denoised\u001b[38;5;241m=\u001b[39mclip_denoised,\n\u001b[1;32m    478\u001b[0m     denoised_fn\u001b[38;5;241m=\u001b[39mdenoised_fn,\n\u001b[1;32m    479\u001b[0m     cond_fn\u001b[38;5;241m=\u001b[39mcond_fn,\n\u001b[1;32m    480\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[1;32m    481\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    482\u001b[0m     progress\u001b[38;5;241m=\u001b[39mprogress,\n\u001b[1;32m    483\u001b[0m ):\n\u001b[1;32m    484\u001b[0m     final \u001b[38;5;241m=\u001b[39m sample\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/data/yjpak/guided-diffusion/guided_diffusion/gaussian_diffusion.py:525\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample_loop_progressive\u001b[0;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress)\u001b[0m\n\u001b[1;32m    523\u001b[0m t \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mtensor([i] \u001b[38;5;241m*\u001b[39m shape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 525\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m out\n\u001b[1;32m    535\u001b[0m     img \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/data/yjpak/guided-diffusion/guided_diffusion/gaussian_diffusion.py:422\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, cond_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_sample\u001b[39m(\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    397\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    404\u001b[0m ):\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    Sample x_{t-1} from the model at the given timestep.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m             - 'pred_xstart': a prediction of x_0.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     noise \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mrandn_like(x)\n\u001b[1;32m    431\u001b[0m     nonzero_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    432\u001b[0m         (t \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m([\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    433\u001b[0m     )  \u001b[38;5;66;03m# no noise when t == 0\u001b[39;00m\n",
      "File \u001b[0;32m/data/yjpak/guided-diffusion/guided_diffusion/respace.py:91\u001b[0m, in \u001b[0;36mSpacedDiffusion.p_mean_variance\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     90\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/yjpak/guided-diffusion/guided_diffusion/gaussian_diffusion.py:290\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     model_variance, model_log_variance \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;66;03m# for fixedlarge, we set the initial (log-)variance like so\u001b[39;00m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;66;03m# to get a better decoder log likelihood.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         ),\n\u001b[1;32m    289\u001b[0m     }[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_var_type]\n\u001b[0;32m--> 290\u001b[0m     model_variance \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_into_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_variance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     model_log_variance \u001b[38;5;241m=\u001b[39m _extract_into_tensor(model_log_variance, t, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_xstart\u001b[39m(x):\n",
      "File \u001b[0;32m/data/yjpak/guided-diffusion/guided_diffusion/gaussian_diffusion.py:905\u001b[0m, in \u001b[0;36m_extract_into_tensor\u001b[0;34m(arr, timesteps, broadcast_shape)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_into_tensor\u001b[39m(arr, timesteps, broadcast_shape):\n\u001b[1;32m    896\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    Extract values from a 1-D numpy array for a batch of indices.\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[timesteps]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(broadcast_shape):\n\u001b[1;32m    907\u001b[0m         res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def cond_fn(x, t, y=None):\n",
    "    assert y is not None\n",
    "    with th.enable_grad():\n",
    "        x_in = x.detach().requires_grad_(True)\n",
    "        logits = classifier(x_in, t)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        selected = log_probs[range(len(logits)), y.view(-1)]\n",
    "        return th.autograd.grad(selected.sum(), x_in)[0] * args.classifier_scale\n",
    "\n",
    "def model_fn(x, t, y=None):\n",
    "    assert y is not None\n",
    "    return model(x, t, y if args.class_cond else None)\n",
    "\n",
    "logger.log(\"sampling...\")\n",
    "all_images = []\n",
    "all_labels = []\n",
    "while len(all_images) * args.batch_size < args.num_samples:\n",
    "    model_kwargs = {}\n",
    "    # classes = th.randint(\n",
    "    #     low=0, high=NUM_CLASSES, size=(args.batch_size,), device=dist_util.dev()\n",
    "    # )\n",
    "    classes = th.full((args.batch_size,), 5, device=dist_util.dev())\n",
    "    model_kwargs[\"y\"] = classes\n",
    "    sample_fn = (\n",
    "        diffusion.p_sample_loop if not args.use_ddim else diffusion.ddim_sample_loop\n",
    "    )\n",
    "    sample = sample_fn(\n",
    "        model_fn,\n",
    "        (args.batch_size, 1, args.image_size, args.image_size),\n",
    "        clip_denoised=args.clip_denoised,\n",
    "        model_kwargs=model_kwargs,\n",
    "        cond_fn=cond_fn,\n",
    "        device=dist_util.dev(),\n",
    "    )\n",
    "\n",
    "    sample = sample.contiguous()\n",
    "\n",
    "    gathered_samples = [th.zeros_like(sample) for _ in range(dist.get_world_size())]\n",
    "    dist.all_gather(gathered_samples, sample)  # gather not supported with NCCL\n",
    "    all_images.extend([sample.cpu().numpy() for sample in gathered_samples])\n",
    "    gathered_labels = [th.zeros_like(classes) for _ in range(dist.get_world_size())]\n",
    "    dist.all_gather(gathered_labels, classes)\n",
    "    all_labels.extend([labels.cpu().numpy() for labels in gathered_labels])\n",
    "    logger.log(f\"created {len(all_images) * args.batch_size} samples\")\n",
    "\n",
    "arr = np.concatenate(all_images, axis=0)\n",
    "arr = arr[: args.num_samples]\n",
    "label_arr = np.concatenate(all_labels, axis=0)\n",
    "label_arr = label_arr[: args.num_samples]\n",
    "if dist.get_rank() == 0:\n",
    "    shape_str = \"x\".join([str(x) for x in arr.shape])\n",
    "    out_path = os.path.join(logger.get_dir(), f\"samples_{shape_str}.npz\")\n",
    "    logger.log(f\"saving to {out_path}\")\n",
    "    np.savez(out_path, arr, label_arr)\n",
    "\n",
    "dist.barrier()\n",
    "logger.log(\"sampling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f13626-475f-447a-b73b-95606da1a76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
