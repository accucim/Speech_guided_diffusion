{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89c19ad-4a99-44e7-9fb8-5e92e3a371af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import blobfile as bf\n",
    "import torch as th\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from guided_diffusion import dist_util, logger\n",
    "from guided_diffusion.fp16_util import MixedPrecisionTrainer\n",
    "from guided_diffusion.image_datasets import load_data\n",
    "from guided_diffusion.resample import create_named_schedule_sampler\n",
    "from guided_diffusion.script_util import (\n",
    "    add_dict_to_argparser,\n",
    "    args_to_dict,\n",
    "    CNN_and_diffusion_defaults,\n",
    "    create_CNN_and_diffusion,\n",
    ")\n",
    "from guided_diffusion.train_util import parse_resume_step_from_filename, log_loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16f9f0c-fea6-49cd-8234-2a97f30967ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if th.cuda.is_available else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6deb218d-8155-4709-af90-09b2ee947d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_argparser():\n",
    "    defaults = dict(\n",
    "        data_dir=\"\",\n",
    "        val_data_dir=\"\",\n",
    "        noised=True, #default: True\n",
    "        iterations=150000,\n",
    "        lr=3e-4,\n",
    "        weight_decay=0.0,\n",
    "        anneal_lr=False,\n",
    "        batch_size=4,\n",
    "        microbatch=-1,\n",
    "        schedule_sampler=\"uniform\",\n",
    "        resume_checkpoint=\"\",\n",
    "        log_interval=10,\n",
    "        eval_interval=5,\n",
    "        save_interval=10000,\n",
    "        doc=\"\"\n",
    "    )\n",
    "    defaults.update(CNN_and_diffusion_defaults())\n",
    "    parser = argparse.ArgumentParser()\n",
    "    add_dict_to_argparser(parser, defaults)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f28f1eb-c733-41c8-912d-75459a4bcaf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# args = create_argparser().parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4afd72a4-3cf1-4609-8993-94ef88c9c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = create_argparser().parse_args(['--data_dir', '/data/yjpak/Dataset/audio_mnist/',\n",
    "                                      '--iterations', '100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f12671-eee5-4bb7-8043-c366a487ba2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data_dir='/data/yjpak/Dataset/audio_mnist/', val_data_dir='', noised=True, iterations=100, lr=0.0003, weight_decay=0.0, anneal_lr=False, batch_size=4, microbatch=-1, schedule_sampler='uniform', resume_checkpoint='', log_interval=10, eval_interval=5, save_interval=10000, doc='', input_channels=1, num_classes=10, image_size=80, learn_sigma=False, diffusion_steps=1000, noise_schedule='linear', timestep_respacing='', use_kl=False, predict_xstart=False, rescale_timesteps=False, rescale_learned_sigmas=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d717a72c-08ef-4e84-8f1c-9ff08fce8b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_dist start\n",
      "os.environ[CUDA_VISIBLE_DEVICES]: 0\n",
      "setup_dist\n"
     ]
    }
   ],
   "source": [
    "dist_util.setup_dist()\n",
    "dist_util.sync_params(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101253c1-ca89-4178-8e4b-63fa16c85022",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_step = 0\n",
    "model, diffusion = create_CNN_and_diffusion(\n",
    "    **args_to_dict(args, CNN_and_diffusion_defaults().keys())\n",
    ")\n",
    "\n",
    "\n",
    "data = load_data(\n",
    "        data_dir=args.data_dir,\n",
    "        batch_size=args.batch_size,\n",
    "        image_size=args.image_size,\n",
    "        class_cond=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffa1849b-7da7-4a8a-9199-21b7f2a9df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "\n",
    "model = DDP(\n",
    "        model,\n",
    "        device_ids=[dist_util.dev()],\n",
    "        output_device=dist_util.dev(),\n",
    "        broadcast_buffers=False,\n",
    "        bucket_cap_mb=128,\n",
    "        find_unused_parameters=False,\n",
    "    )\n",
    "\n",
    "if args.noised:\n",
    "    schedule_sampler = create_named_schedule_sampler(\n",
    "        args.schedule_sampler, diffusion\n",
    "    )\n",
    "\n",
    "mp_trainer = MixedPrecisionTrainer(\n",
    "        model=model, initial_lg_loss_scale=16.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d081597-ec1d-46b6-8f96-d4d4a1a7b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_annealed_lr(opt, base_lr, frac_done):\n",
    "    lr = base_lr * (1 - frac_done)\n",
    "    for param_group in opt.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "def split_microbatches(microbatch, *args):\n",
    "    bs = len(args[0])\n",
    "    if microbatch == -1 or microbatch >= bs:\n",
    "        yield tuple(args)\n",
    "    else:\n",
    "        for i in range(0, bs, microbatch):\n",
    "            yield tuple(x[i : i + microbatch] if x is not None else None for x in args)\n",
    "\n",
    "def compute_top_k(logits, labels, k, reduction=\"mean\"):\n",
    "    _, top_ks = th.topk(logits, k, dim=-1)\n",
    "    if reduction == \"mean\":\n",
    "        return (top_ks == labels[:, None]).float().sum(dim=-1).mean().item()\n",
    "    elif reduction == \"none\":\n",
    "        return (top_ks == labels[:, None]).float().sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e050d2f-20ce-4ccc-9fdb-dfc677dec057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating optimizer...\n",
      "training classifier model...\n"
     ]
    }
   ],
   "source": [
    "logger.log(f\"creating optimizer...\")\n",
    "opt = AdamW(mp_trainer.master_params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "logger.log(\"training classifier model...\")\n",
    "\n",
    "def forward_backward_log(data_loader, prefix=\"train\"):\n",
    "    batch, extra = next(data_loader)\n",
    "    labels = extra[\"y\"].to(dist_util.dev())\n",
    "    batch = batch.to(dist_util.dev())\n",
    "    \n",
    "    # Noisy images\n",
    "    if args.noised:\n",
    "        t, _ = schedule_sampler.sample(batch.shape[0], dist_util.dev())\n",
    "        print(\"noise t: \", t.shape)\n",
    "        batch = diffusion.q_sample(batch, t)            \n",
    "    else:\n",
    "        t = th.zeros(batch.shape[0], dtype=th.long, device=dist_util.dev())\n",
    "\n",
    "    for i, (sub_batch, sub_labels, sub_t) in enumerate(\n",
    "        split_microbatches(args.microbatch, batch, labels, t)\n",
    "    ):\n",
    "        # np.save(f\"/data/yjpak/guided-diffusion/logs/batch_check/sub_batch_{dist.get_rank()}\", sub_batch.detach().cpu().numpy())\n",
    "        # np.save(f\"/data/yjpak/guided-diffusion/logs/batch_check/sub_labels_{dist.get_rank()}\", sub_labels.detach().cpu().numpy())\n",
    "        logits = model(sub_batch, timesteps=sub_t)\n",
    "        loss = F.cross_entropy(logits, sub_labels, reduction=\"none\")\n",
    "\n",
    "        losses = {}\n",
    "        losses[f\"{prefix}_loss\"] = loss.detach()\n",
    "        losses[f\"{prefix}_acc@1\"] = compute_top_k(\n",
    "            logits, sub_labels, k=1, reduction=\"none\"\n",
    "        )\n",
    "\n",
    "        log_loss_dict(diffusion, sub_t, losses)\n",
    "        del losses\n",
    "        loss = loss.mean()\n",
    "        if loss.requires_grad:\n",
    "            if i == 0:\n",
    "                mp_trainer.zero_grad()\n",
    "            mp_trainer.backward(loss * len(sub_batch) / len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329064be-b9d3-4d41-a640-1dfa53cac0c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.41     |\n",
      "| param_norm     | 38.2     |\n",
      "| samples        | 4        |\n",
      "| step           | 0        |\n",
      "| train_acc@1    | 0.0682   |\n",
      "| train_acc@1_q0 | 0        |\n",
      "| train_acc@1_q1 | 0        |\n",
      "| train_acc@1_q2 | 0.2      |\n",
      "| train_acc@1_q3 | 0.0625   |\n",
      "| train_loss     | 2.33     |\n",
      "| train_loss_q0  | 2.28     |\n",
      "| train_loss_q1  | 2.34     |\n",
      "| train_loss_q2  | 2.3      |\n",
      "| train_loss_q3  | 2.38     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.18     |\n",
      "| param_norm     | 38.3     |\n",
      "| samples        | 44       |\n",
      "| step           | 10       |\n",
      "| train_acc@1    | 0.075    |\n",
      "| train_acc@1_q0 | 0        |\n",
      "| train_acc@1_q1 | 0.0769   |\n",
      "| train_acc@1_q2 | 0.1      |\n",
      "| train_acc@1_q3 | 0.1      |\n",
      "| train_loss     | 2.32     |\n",
      "| train_loss_q0  | 2.35     |\n",
      "| train_loss_q1  | 2.34     |\n",
      "| train_loss_q2  | 2.3      |\n",
      "| train_loss_q3  | 2.32     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.52     |\n",
      "| param_norm     | 38.3     |\n",
      "| samples        | 84       |\n",
      "| step           | 20       |\n",
      "| train_acc@1    | 0.05     |\n",
      "| train_acc@1_q0 | 0        |\n",
      "| train_acc@1_q1 | 0.1      |\n",
      "| train_acc@1_q2 | 0.0769   |\n",
      "| train_acc@1_q3 | 0        |\n",
      "| train_loss     | 2.37     |\n",
      "| train_loss_q0  | 2.52     |\n",
      "| train_loss_q1  | 2.37     |\n",
      "| train_loss_q2  | 2.32     |\n",
      "| train_loss_q3  | 2.34     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.34     |\n",
      "| param_norm     | 38.3     |\n",
      "| samples        | 124      |\n",
      "| step           | 30       |\n",
      "| train_acc@1    | 0.25     |\n",
      "| train_acc@1_q0 | 0.25     |\n",
      "| train_acc@1_q1 | 0.3      |\n",
      "| train_acc@1_q2 | 0.5      |\n",
      "| train_acc@1_q3 | 0        |\n",
      "| train_loss     | 2.26     |\n",
      "| train_loss_q0  | 2.31     |\n",
      "| train_loss_q1  | 2.32     |\n",
      "| train_loss_q2  | 2.17     |\n",
      "| train_loss_q3  | 2.22     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.46     |\n",
      "| param_norm     | 38.3     |\n",
      "| samples        | 164      |\n",
      "| step           | 40       |\n",
      "| train_acc@1    | 0.075    |\n",
      "| train_acc@1_q0 | 0.125    |\n",
      "| train_acc@1_q1 | 0.1      |\n",
      "| train_acc@1_q2 | 0        |\n",
      "| train_acc@1_q3 | 0.0769   |\n",
      "| train_loss     | 2.33     |\n",
      "| train_loss_q0  | 2.36     |\n",
      "| train_loss_q1  | 2.24     |\n",
      "| train_loss_q2  | 2.37     |\n",
      "| train_loss_q3  | 2.37     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.02     |\n",
      "| param_norm     | 38.3     |\n",
      "| samples        | 204      |\n",
      "| step           | 50       |\n",
      "| train_acc@1    | 0.125    |\n",
      "| train_acc@1_q0 | 0.0909   |\n",
      "| train_acc@1_q1 | 0.182    |\n",
      "| train_acc@1_q2 | 0.111    |\n",
      "| train_acc@1_q3 | 0.111    |\n",
      "| train_loss     | 2.27     |\n",
      "| train_loss_q0  | 2.21     |\n",
      "| train_loss_q1  | 2.29     |\n",
      "| train_loss_q2  | 2.25     |\n",
      "| train_loss_q3  | 2.35     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.44     |\n",
      "| param_norm     | 38.4     |\n",
      "| samples        | 244      |\n",
      "| step           | 60       |\n",
      "| train_acc@1    | 0.1      |\n",
      "| train_acc@1_q0 | 0.125    |\n",
      "| train_acc@1_q1 | 0.133    |\n",
      "| train_acc@1_q2 | 0.111    |\n",
      "| train_acc@1_q3 | 0        |\n",
      "| train_loss     | 2.31     |\n",
      "| train_loss_q0  | 2.25     |\n",
      "| train_loss_q1  | 2.33     |\n",
      "| train_loss_q2  | 2.33     |\n",
      "| train_loss_q3  | 2.32     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 2.94     |\n",
      "| param_norm     | 38.4     |\n",
      "| samples        | 284      |\n",
      "| step           | 70       |\n",
      "| train_acc@1    | 0.1      |\n",
      "| train_acc@1_q0 | 0        |\n",
      "| train_acc@1_q1 | 0        |\n",
      "| train_acc@1_q2 | 0.3      |\n",
      "| train_acc@1_q3 | 0.125    |\n",
      "| train_loss     | 2.34     |\n",
      "| train_loss_q0  | 2.41     |\n",
      "| train_loss_q1  | 2.34     |\n",
      "| train_loss_q2  | 2.23     |\n",
      "| train_loss_q3  | 2.39     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.45     |\n",
      "| param_norm     | 38.4     |\n",
      "| samples        | 324      |\n",
      "| step           | 80       |\n",
      "| train_acc@1    | 0.1      |\n",
      "| train_acc@1_q0 | 0.111    |\n",
      "| train_acc@1_q1 | 0.182    |\n",
      "| train_acc@1_q2 | 0.1      |\n",
      "| train_acc@1_q3 | 0        |\n",
      "| train_loss     | 2.27     |\n",
      "| train_loss_q0  | 2.31     |\n",
      "| train_loss_q1  | 2.19     |\n",
      "| train_loss_q2  | 2.28     |\n",
      "| train_loss_q3  | 2.32     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "-----------------------------\n",
      "| grad_norm      | 3.39     |\n",
      "| param_norm     | 38.4     |\n",
      "| samples        | 364      |\n",
      "| step           | 90       |\n",
      "| train_acc@1    | 0.1      |\n",
      "| train_acc@1_q0 | 0.154    |\n",
      "| train_acc@1_q1 | 0        |\n",
      "| train_acc@1_q2 | 0.0909   |\n",
      "| train_acc@1_q3 | 0.111    |\n",
      "| train_loss     | 2.33     |\n",
      "| train_loss_q0  | 2.24     |\n",
      "| train_loss_q1  | 2.28     |\n",
      "| train_loss_q2  | 2.37     |\n",
      "| train_loss_q3  | 2.45     |\n",
      "-----------------------------\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "noise t:  torch.Size([4])\n",
      "saving model...\n"
     ]
    }
   ],
   "source": [
    "for step in range(args.iterations - resume_step):\n",
    "    logger.logkv(\"step\", step + resume_step)\n",
    "    logger.logkv(\n",
    "        \"samples\",\n",
    "        (step + resume_step + 1) * args.batch_size * dist.get_world_size(),\n",
    "    )\n",
    "    if args.anneal_lr:\n",
    "        set_annealed_lr(opt, args.lr, (step + resume_step) / args.iterations)\n",
    "        \n",
    "    forward_backward_log(data)\n",
    "    mp_trainer.optimize(opt)\n",
    "    \n",
    "    if not step % args.log_interval:\n",
    "        logger.dumpkvs()\n",
    "    if (\n",
    "        step\n",
    "        and dist.get_rank() == 0\n",
    "        and not (step + resume_step) % args.save_interval\n",
    "    ):\n",
    "        logger.log(\"saving model...\")\n",
    "        save_model(mp_trainer, opt, step + resume_step)\n",
    "\n",
    "if dist.get_rank() == 0:\n",
    "    logger.log(\"saving model...\")\n",
    "    save_model(mp_trainer, opt, step + resume_step)\n",
    "else:\n",
    "    print(\"dist.get_rank = 1\")\n",
    "dist.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64af3815-a7e9-41e3-8e4e-62d100cd12ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_2D(\n",
       "  (layer1_conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1_conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1_bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer2_conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer2_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer2_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer2_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer2_bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer3_conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer3_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer3_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer4_conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer4_bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer4_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer4_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer4_bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (emb_layers1): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  )\n",
       "  (emb_layers2): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (emb_layers3): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (emb_layers4): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adadba-8d19-421c-8f9a-aa40fded282d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f8bfa-e06a-43fc-b3a6-74101df52757",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpiexec -n 2 python model_analysis.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
